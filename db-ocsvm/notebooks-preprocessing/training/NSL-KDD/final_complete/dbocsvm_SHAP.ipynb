{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sample_size = 0.01\n",
    "use_sample = True\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "onnx_path = \"autoencoder.onnx\"\n",
    "\n",
    "trained_model_path = \"saved_models/autoencoder_Model_1_hidden[96, 64, 48, 32]_latent16_lr0.01_bs256_optadamw_actGELU_dr0.1_wd0.001.pth\"\n",
    "existing_model_architecture = {\n",
    "    \"input_dim\": 122,\n",
    "    \"hidden_dims\": [96, 64, 48, 32],\n",
    "    \"latent_dim\": 16,\n",
    "    \"activation_type\": \"GELU\",\n",
    "    \"negative_slope\": 0,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"output_activation_type\": \"Sigmoid\",\n",
    "}\n",
    "\n",
    "new_model_architecture = {\n",
    "    \"hidden_dims\": [96, 64],\n",
    "    \"latent_dim\": 55,\n",
    "    \"activation_type\": \"LeakyReLU\",\n",
    "    \"output_activation_type\": \"Sigmoid\",\n",
    "}\n",
    "\n",
    "new_model_learning_parameters = {\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_epochs\": 100,\n",
    "    \"improvement_threshold\": 0.000000001,\n",
    "    \"good_model_threshold\": 0.00015,\n",
    "    \"early_stopping_patience\": 10,\n",
    "}\n",
    "\n",
    "train_set_path = \"/home/jbct/Projects/thesis/db-ocsvm/data/processed/NSL-KDD/minamax_scaler_new/train_set.csv\"\n",
    "test_set_path = \"/home/jbct/Projects/thesis/db-ocsvm/data/processed/NSL-KDD/minamax_scaler_new/test_set.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_parameters = {\n",
    "    \"eps\": 1.787311276337387,\n",
    "    \"min_samples\": 29,\n",
    "    \"distance_metric\": \"manhattan\",\n",
    "    \"score\": 0.4514608383178711,\n",
    "}\n",
    "\n",
    "tree_alogrithm_parameter = \"ball_tree\"\n",
    "\n",
    "dbocsvm_parameter_list = {\n",
    "    0: {\"kernel\": \"rbf\", \"gamma\": 0.6749850177017664, \"nu\": 0.3956772361821075},\n",
    "    1: {\"kernel\": \"rbf\", \"gamma\": 0.5382840782127776, \"nu\": 0.011519277593471742},\n",
    "    2: {\"kernel\": \"rbf\", \"gamma\": 0.6760178250552376, \"nu\": 0.06307402235246268},\n",
    "    3: {\"kernel\": \"rbf\", \"gamma\": 0.7126590670330865, \"nu\": 0.06057021076474931},\n",
    "    4: {\"kernel\": \"rbf\", \"gamma\": 0.43393514090957325, \"nu\": 0.0714240292185416},\n",
    "    5: {\"kernel\": \"rbf\", \"gamma\": 0.9517259890980925, \"nu\": 0.3276133623126268},\n",
    "    6: {\"kernel\": \"rbf\", \"gamma\": 0.2105087862996638, \"nu\": 0.10704277141309872},\n",
    "    7: {\"kernel\": \"rbf\", \"gamma\": 0.40570553555679434, \"nu\": 0.4854848861673181},\n",
    "    8: {\"kernel\": \"rbf\", \"gamma\": 0.7437204380559609, \"nu\": 0.3450585844550152},\n",
    "    9: {\"kernel\": \"rbf\", \"gamma\": 0.4904715339167893, \"nu\": 0.05866339891711346},\n",
    "    10: {\"kernel\": \"rbf\", \"gamma\": 0.3525616981336645, \"nu\": 0.11258335148635641},\n",
    "    11: {\"kernel\": \"rbf\", \"gamma\": 0.8394655474399617, \"nu\": 0.014396303218355359},\n",
    "    12: {\"kernel\": \"rbf\", \"gamma\": 0.966790981718318, \"nu\": 0.35955258309738003},\n",
    "    13: {\"kernel\": \"rbf\", \"gamma\": 0.40569205407720194, \"nu\": 0.15473416045029326},\n",
    "    14: {\"kernel\": \"rbf\", \"gamma\": 0.7802232942940553, \"nu\": 0.33277673425852156},\n",
    "    15: {\"kernel\": \"rbf\", \"gamma\": 0.47913938510822796, \"nu\": 0.0849304514637937},\n",
    "    16: {\"kernel\": \"rbf\", \"gamma\": 0.8815413846424647, \"nu\": 0.06496299084584861},\n",
    "    17: {\"kernel\": \"rbf\", \"gamma\": 0.658179889282608, \"nu\": 0.2958789542792919},\n",
    "    18: {\"kernel\": \"rbf\", \"gamma\": 0.2656093223502789, \"nu\": 0.23132614193252973},\n",
    "    19: {\"kernel\": \"rbf\", \"gamma\": 0.9288753597450893, \"nu\": 0.4523412126896116},\n",
    "    20: {\"kernel\": \"rbf\", \"gamma\": 0.1537475516837271, \"nu\": 0.23998315552744287},\n",
    "    21: {\"kernel\": \"rbf\", \"gamma\": 0.7440255543987286, \"nu\": 0.012471419048979998},\n",
    "    22: {\"kernel\": \"rbf\", \"gamma\": 0.6826805563290459, \"nu\": 0.2088530681181794},\n",
    "    23: {\"kernel\": \"rbf\", \"gamma\": 0.5720789151209829, \"nu\": 0.34361483253223735},\n",
    "    24: {\"kernel\": \"rbf\", \"gamma\": 0.5091042324615142, \"nu\": 0.18362802550012192},\n",
    "    25: {\"kernel\": \"rbf\", \"gamma\": 0.39324526774738006, \"nu\": 0.30018911635517903},\n",
    "    26: {\"kernel\": \"rbf\", \"gamma\": 0.11072003753199025, \"nu\": 0.10562894182999995},\n",
    "    27: {\"kernel\": \"rbf\", \"gamma\": 0.16060182837914166, \"nu\": 0.1625869530357687},\n",
    "    28: {\"kernel\": \"rbf\", \"gamma\": 0.8862387459902442, \"nu\": 0.2856752422997735},\n",
    "    29: {\"kernel\": \"rbf\", \"gamma\": 0.7737268500004805, \"nu\": 0.06490415711757859},\n",
    "    30: {\"kernel\": \"rbf\", \"gamma\": 0.2982692363201671, \"nu\": 0.2682792918743827},\n",
    "    31: {\"kernel\": \"rbf\", \"gamma\": 0.9593034375847778, \"nu\": 0.4234419103858413},\n",
    "    32: {\"kernel\": \"rbf\", \"gamma\": 0.5510395673977838, \"nu\": 0.35802896324024025},\n",
    "    33: {\"kernel\": \"rbf\", \"gamma\": 0.7628631528017598, \"nu\": 0.45754063046701976},\n",
    "    34: {\"kernel\": \"rbf\", \"gamma\": 0.9610045012036982, \"nu\": 0.4350232780924957},\n",
    "    35: {\"kernel\": \"rbf\", \"gamma\": 0.9043870319578275, \"nu\": 0.12459124094840476},\n",
    "    36: {\"kernel\": \"rbf\", \"gamma\": 0.776877026765261, \"nu\": 0.4866898392064121},\n",
    "    37: {\"kernel\": \"rbf\", \"gamma\": 0.9972865655411062, \"nu\": 0.2749360631616554},\n",
    "    38: {\"kernel\": \"rbf\", \"gamma\": 0.642919009119658, \"nu\": 0.2641844103392809},\n",
    "    39: {\"kernel\": \"rbf\", \"gamma\": 0.6207461915783272, \"nu\": 0.09963239899111537},\n",
    "    40: {\"kernel\": \"rbf\", \"gamma\": 0.5995094745977826, \"nu\": 0.10752175690717974},\n",
    "    41: {\"kernel\": \"rbf\", \"gamma\": 0.7602690087833293, \"nu\": 0.1408885493562113},\n",
    "    42: {\"kernel\": \"rbf\", \"gamma\": 0.8795809728492018, \"nu\": 0.13314053460265152},\n",
    "    43: {\"kernel\": \"rbf\", \"gamma\": 0.21020522465525246, \"nu\": 0.4389780274338308},\n",
    "    44: {\"kernel\": \"rbf\", \"gamma\": 0.3112507342569375, \"nu\": 0.03783535940274117},\n",
    "    45: {\"kernel\": \"rbf\", \"gamma\": 0.024006951870270698, \"nu\": 0.03369206491746739},\n",
    "    46: {\"kernel\": \"rbf\", \"gamma\": 0.15046762791657775, \"nu\": 0.2247197624426874},\n",
    "    47: {\"kernel\": \"rbf\", \"gamma\": 0.8585461277526101, \"nu\": 0.3057315857770464},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(train_set_path)\n",
    "if use_sample:\n",
    "    train_df = train_df.sample(frac=sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.values\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "\n",
    "# Create data loaders\n",
    "X_train_dataset = TensorDataset(X_train_tensor)\n",
    "\n",
    "input_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load trained autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import BatchNormAutoencoderV2\n",
    "\n",
    "autoencoder = BatchNormAutoencoderV2(\n",
    "    input_dim=existing_model_architecture[\"input_dim\"],\n",
    "    hidden_dims=existing_model_architecture[\"hidden_dims\"],\n",
    "    latent_dim=existing_model_architecture[\"latent_dim\"],\n",
    "    activation_type=existing_model_architecture[\"activation_type\"],\n",
    "    negative_slope=existing_model_architecture[\"negative_slope\"],\n",
    "    dropout_rate=existing_model_architecture[\"dropout_rate\"],\n",
    "    output_activation_type=existing_model_architecture[\"output_activation_type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(trained_model_path)\n",
    "autoencoder.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "autoencoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_set_path)\n",
    "print(test_df.shape)\n",
    "print(test_df[\"attack_class\"].value_counts())\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into X and y\n",
    "X_test = test_df.drop(\n",
    "    columns=[\"attack_binary\", \"attack_categorical\", \"attack_class\"]\n",
    ").values\n",
    "y_test = test_df[\"attack_binary\"].values\n",
    "y_test_class = test_df[\"attack_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a wrapper function for the autoencoder that returns reconstruction error\n",
    "class AutoencoderWrapper:\n",
    "    def __init__(self, autoencoder):\n",
    "        self.autoencoder = autoencoder\n",
    "\n",
    "    def __call__(self, X):\n",
    "        # Convert to tensor\n",
    "        X_tensor = torch.FloatTensor(X).to(device)\n",
    "\n",
    "        # Get reconstruction\n",
    "        with torch.no_grad():\n",
    "            reconstructed = self.autoencoder(X_tensor)\n",
    "\n",
    "        # Calculate reconstruction error per sample\n",
    "        reconstruction_error = (\n",
    "            ((reconstructed - X_tensor) ** 2).mean(dim=1).cpu().numpy()\n",
    "        )\n",
    "        return reconstruction_error\n",
    "\n",
    "\n",
    "# Initialize the wrapper\n",
    "model_wrapper = AutoencoderWrapper(autoencoder)\n",
    "\n",
    "# Create a background dataset (subset of training data)\n",
    "# background_data = X_train_full[:1000]  # Using a subset for computational efficiency\n",
    "background_data = shap.kmeans(X_train, 100)  # Use 100 representative centroids\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "explainer = shap.KernelExplainer(model_wrapper, background_data)\n",
    "\n",
    "# Sample a subset of test data for SHAP analysis (for efficiency)\n",
    "test_sample_indices = np.random.choice(\n",
    "    len(X_test), min(500, len(X_test)), replace=False\n",
    ")\n",
    "test_sample = X_test[test_sample_indices]\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert test_sample to DataFrame with feature names\n",
    "feature_names = test_df.drop(\n",
    "    columns=[\"attack_binary\", \"attack_categorical\", \"attack_class\"]\n",
    ").columns\n",
    "test_sample_df = pd.DataFrame(test_sample, columns=feature_names)\n",
    "\n",
    "# Alternative approach for SHAP feature importance visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Calculate mean absolute SHAP values for each feature\n",
    "feature_importance = np.abs(shap_values).mean(0)\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": feature_names, \"Importance\": feature_importance}\n",
    ")\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(\n",
    "    \"Importance\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Take top 20 features\n",
    "top_features = feature_importance_df.head(20)\n",
    "\n",
    "# Create standard matplotlib bar plot\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=top_features)\n",
    "plt.title(\"Feature Importance Based on SHAP Values\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_feature_importance_alt.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# The second plot might work with the direct SHAP approach\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values, test_sample_df, max_display=20, show=False)\n",
    "plt.title(\"Feature Impact on Reconstruction Error\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_feature_impact.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Calculate reconstruction errors for all test data\n",
    "def calculate_reconstruction_errors(data, model):\n",
    "    errors = []\n",
    "    batch_size = 256\n",
    "    data_tensor = torch.FloatTensor(data).to(device)\n",
    "    dataset = TensorDataset(data_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs = batch[0]\n",
    "            outputs = model(inputs)\n",
    "            error = ((outputs - inputs) ** 2).mean(dim=1)\n",
    "            errors.append(error.cpu().numpy())\n",
    "\n",
    "    return np.concatenate(errors)\n",
    "\n",
    "\n",
    "# Get reconstruction errors for test data\n",
    "test_errors = calculate_reconstruction_errors(X_test, autoencoder)\n",
    "\n",
    "# Plot distribution of reconstruction errors by class\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(test_errors[y_test == 1], bins=50, alpha=0.5, label=\"Normal\", density=True)\n",
    "plt.hist(test_errors[y_test == -1], bins=50, alpha=0.5, label=\"Anomaly\", density=True)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Reconstruction Error\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of Reconstruction Errors by Class\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlations between feature values and reconstruction error\n",
    "feature_names = test_df.drop(\n",
    "    columns=[\"attack_binary\", \"attack_categorical\", \"attack_class\"]\n",
    ").columns\n",
    "correlations = []\n",
    "\n",
    "for i in range(X_test.shape[1]):\n",
    "    corr = np.corrcoef(X_test[:, i], test_errors)[0, 1]\n",
    "    correlations.append((feature_names[i], abs(corr)))\n",
    "\n",
    "# Sort by correlation strength\n",
    "correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Plot top 20 correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = [x[0] for x in correlations[:20]]\n",
    "top_correlations = [x[1] for x in correlations[:20]]\n",
    "plt.barh(top_features, top_correlations)\n",
    "plt.xlabel(\"Absolute Correlation with Reconstruction Error\")\n",
    "plt.title(\"Top 20 Features Correlated with Reconstruction Error\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Print top 10 most important features according to SHAP\n",
    "feature_importance = np.abs(shap_values).mean(0)\n",
    "feature_importance_dict = {\n",
    "    feature_names[i]: feature_importance[i] for i in range(len(feature_names))\n",
    "}\n",
    "sorted_features = sorted(\n",
    "    feature_importance_dict.items(), key=lambda x: x[1], reverse=True\n",
    ")\n",
    "\n",
    "print(\"Top 10 most important features according to SHAP analysis:\")\n",
    "for feature, importance in sorted_features[:10]:\n",
    "    print(f\"{feature}: {importance:.6f}\")\n",
    "\n",
    "# Compare with correlation analysis\n",
    "print(\"\\nTop 10 features most correlated with reconstruction error:\")\n",
    "for feature, correlation in correlations[:10]:\n",
    "    print(f\"{feature}: {correlation:.6f}\")\n",
    "\n",
    "# Calculate how many anomalies could be detected by reconstruction error alone\n",
    "# using a simple threshold-based approach\n",
    "\n",
    "# Find optimal threshold\n",
    "precision, recall, thresholds = precision_recall_curve(y_test == -1, test_errors)\n",
    "f1_scores = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# Apply threshold\n",
    "predicted_anomalies = test_errors > optimal_threshold\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = np.mean(predicted_anomalies == (y_test == -1))\n",
    "precision = np.sum(predicted_anomalies & (y_test == -1)) / (\n",
    "    np.sum(predicted_anomalies) + 1e-10\n",
    ")\n",
    "recall = np.sum(predicted_anomalies & (y_test == -1)) / (np.sum(y_test == -1) + 1e-10)\n",
    "f1 = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "\n",
    "print(f\"\\nUsing only reconstruction error for anomaly detection:\")\n",
    "print(f\"Optimal threshold: {optimal_threshold:.6f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\n",
    "    \"\\nCompared to the hybrid DBOCSVM model performance above, we can see how the clustering and\"\n",
    ")\n",
    "print(\n",
    "    \"multiple One-Class SVM approach enhances detection compared to using reconstruction error alone.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the DBOCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# extract encoded features\n",
    "X_train_loader = DataLoader(X_train_dataset, batch_size=256)\n",
    "\n",
    "# Extract in batches to prevent memory issues\n",
    "X_train_full_encoded = []\n",
    "with torch.no_grad():\n",
    "    for data in X_train_loader:\n",
    "        data_x = data[0].to(device)\n",
    "        encoded = autoencoder.encode(data_x)\n",
    "        X_train_full_encoded.append(encoded.cpu().numpy())\n",
    "X_train_full_encoded = np.vstack(X_train_full_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_ocsvm_04 import DBOCSVM\n",
    "\n",
    "dbocsvm = DBOCSVM(\n",
    "    kernel=\"rbf\",\n",
    "    gamma=\"auto\",\n",
    "    nu=0.2,\n",
    "    eps=dbscan_parameters[\"eps\"],\n",
    "    min_samples=dbscan_parameters[\"min_samples\"],\n",
    "    dbscan_distance_metric=dbscan_parameters[\"distance_metric\"],\n",
    "    tree_algorithm=tree_alogrithm_parameter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbocsvm.fit_cluster(X_train_full_encoded, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbocsvm.fit_ocsvm(X_train_full_encoded, parameter_list=dbocsvm_parameter_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "X_test_encoded = []\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.zeros(len(X_test_tensor)))\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, _ in test_loader:\n",
    "        encoded = autoencoder.encode(data)\n",
    "        X_test_encoded.append(encoded.cpu().numpy())\n",
    "\n",
    "X_test_encoded = np.vstack(X_test_encoded)\n",
    "print(X_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dbocsvm.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[-1, 1])\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title):\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels\n",
    "    )\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"Actual Label\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm, [\"Anomaly\", \"Normal\"], \"Confusion Matrix (Anomaly vs Normal)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Anomaly\", \"Normal\"]))\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=-1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=-1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=-1)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1_1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(f\"Precision: {precision_1}\")\n",
    "print(f\"Recall: {recall_1}\")\n",
    "print(f\"F1 Score: {f1_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiclass_cm(y_true_class, y_pred_binary):\n",
    "    \"\"\"\n",
    "    Create a confusion matrix showing how each attack class was classified.\n",
    "\n",
    "    For attack classes (DoS, Probe, R2L, U2R), correct detection is when y_pred = -1 (anomaly)\n",
    "    For normal class, correct detection is when y_pred = 1 (normal)\n",
    "    \"\"\"\n",
    "    classes = np.unique(y_true_class)\n",
    "    cm = np.zeros((len(classes), 2))\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        # Get predictions for this class\n",
    "        cls_indices = y_true_class == cls\n",
    "        preds = y_pred_binary[cls_indices]\n",
    "\n",
    "        # Count correct and incorrect predictions\n",
    "        if cls == \"normal\":\n",
    "            cm[i, 0] = np.sum(preds == -1)  # incorrectly detected as anomaly\n",
    "            cm[i, 1] = np.sum(preds == 1)  # correctly detected as normal\n",
    "        else:\n",
    "            cm[i, 0] = np.sum(preds == -1)  # correctly detected as anomaly\n",
    "            cm[i, 1] = np.sum(preds == 1)  # incorrectly detected as normal\n",
    "\n",
    "    return cm, classes\n",
    "\n",
    "\n",
    "# Create and plot the multi-class confusion matrix\n",
    "cm_multi, classes = create_multiclass_cm(y_test_class, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm_multi,\n",
    "    annot=True,\n",
    "    fmt=\"g\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Detected as Anomaly\", \"Detected as Normal\"],\n",
    "    yticklabels=classes,\n",
    ")\n",
    "plt.ylabel(\"True Attack Class\")\n",
    "plt.title(\"Confusion Matrix by Attack Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate detection rates for each class\n",
    "print(\"Detection rates by class:\")\n",
    "class_metrics = {}\n",
    "for cls in np.unique(y_test_class):\n",
    "    # Get indices for this class\n",
    "    class_indices = y_test_class == cls\n",
    "\n",
    "    # True values and predictions for this class\n",
    "    y_true_cls = y_test[class_indices]\n",
    "    y_pred_cls = y_pred[class_indices]\n",
    "\n",
    "    # Calculate metrics\n",
    "    if cls == \"Normal\":\n",
    "        # For normal class, we want to detect 1 (normal)\n",
    "        correct = np.sum((y_pred_cls == 1))\n",
    "        precision = precision_score(\n",
    "            y_true_cls, y_pred_cls, pos_label=1, zero_division=0\n",
    "        )\n",
    "        recall = recall_score(y_true_cls, y_pred_cls, pos_label=1, zero_division=0)\n",
    "    else:\n",
    "        # For attack classes, we want to detect -1 (anomaly)\n",
    "        correct = np.sum((y_pred_cls == -1))\n",
    "        precision = precision_score(\n",
    "            y_true_cls, y_pred_cls, pos_label=-1, zero_division=0\n",
    "        )\n",
    "        recall = recall_score(y_true_cls, y_pred_cls, pos_label=-1, zero_division=0)\n",
    "\n",
    "    total = len(y_pred_cls)\n",
    "    detection_rate = correct / total\n",
    "    f1 = f1_score(\n",
    "        y_true_cls, y_pred_cls, pos_label=-1 if cls != \"Normal\" else 1, zero_division=0\n",
    "    )\n",
    "\n",
    "    class_metrics[cls] = {\n",
    "        \"detection_rate\": detection_rate,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"count\": total,\n",
    "        \"correctly_detected\": correct,\n",
    "    }\n",
    "\n",
    "    print(f\"{cls}: {detection_rate:.4f} ({correct}/{total})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
