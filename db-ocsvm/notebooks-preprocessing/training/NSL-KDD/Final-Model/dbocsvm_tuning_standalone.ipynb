{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbct/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List, Optional\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import KDTree, BallTree\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from models import BatchNormAutoencoder, DBOCSVM\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    ")\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with_storage_dbscan = False\n",
    "with_storage_dbocsvm = False\n",
    "dbscan_optuna_storage_path = \"sqlite:///optuna_storage/dbscan_study.db\"\n",
    "ocsvm_optuna_storage_path = \"sqlite:///optuna_storage/dbocsvm_study.db\"\n",
    "\n",
    "# Only need to change sample size, dataset paths, with_storage, ocsvm_trials\n",
    "\n",
    "sample_size = 0.01\n",
    "use_sample = True\n",
    "\n",
    "use_full_train_set = True\n",
    "\n",
    "best_model_path = \"best_models/best_model_proposed.pth\"\n",
    "\n",
    "export_model = True\n",
    "onnx_path = \"saved_models/autoencoder.onnx\"\n",
    "\n",
    "use_existing_model = False\n",
    "existing_model_path = (\n",
    "    \"saved_models/autoencoder_Model_1_hidden[96, 64]_latent55_best.pth\"\n",
    ")\n",
    "\n",
    "existing_model_architecture = {\n",
    "    \"input_dim\": 122,\n",
    "    \"hidden_dims\": [96, 64],\n",
    "    \"latent_dim\": 55,\n",
    "    \"activation_type\": \"LeakyReLU\",\n",
    "    \"output_activation_type\": \"Sigmoid\",\n",
    "}\n",
    "\n",
    "train_set_path = (\n",
    "    \"/home/jbct/Projects/thesis/db-ocsvm/data/processed/NSL-KDD/train_set_full.csv\"\n",
    ")\n",
    "test_set_path = (\n",
    "    \"/home/jbct/Projects/thesis/db-ocsvm/data/processed/NSL-KDD/test_set.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture if not using existing model\n",
    "new_model_architecture = {\n",
    "    \"hidden_dims\": [116, 96, 64, 48],\n",
    "    \"latent_dim\": 22,\n",
    "    \"activation_type\": \"LeakyReLU\",\n",
    "    \"output_activation_type\": \"Sigmoid\",\n",
    "}\n",
    "\n",
    "new_model_learning_parameters = {\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 50,\n",
    "    \"improvement_threshold\": 0.000000001,\n",
    "    \"good_model_threshold\": 0.00015,\n",
    "    \"early_stopping_patience\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_tuning_parameters = {\n",
    "    \"evaluation_metric\": \"silhouette\",  # silhouette, calinski_harabasz, davies_bouldin\n",
    "    \"distance_metric\": \"manhattan\",  # manhattan, euclidean\n",
    "    \"trials\": 10,\n",
    "}\n",
    "\n",
    "dbocsvm_tree_algorithm = \"kd_tree\"  # \"ball_tree\" or \"kd_tree\"\n",
    "\n",
    "ocsvm_trials = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(673, 122)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.833486e-07</td>\n",
       "      <td>2.572642e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration     src_bytes     dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0       0.0  5.833486e-07  2.572642e-07   0.0             0.0     0.0  0.0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                0.0        1.0              0.0  ...       0.0        0.0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0          0.0        0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "\n",
       "   flag_SH  \n",
       "0      0.0  \n",
       "\n",
       "[1 rows x 122 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(train_set_path)\n",
    "\n",
    "if use_sample:\n",
    "    train_df = train_df.sample(frac=sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538, 122) (135, 122) (673, 122)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full = train_df.values\n",
    "\n",
    "X_train, X_val = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "X_train = X_train.values\n",
    "X_val = X_val.values\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_train_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor)\n",
    "\n",
    "input_dim = X_train_full.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training the autoencoder or use existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class BatchNormAutoencoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 128,\n",
    "        hidden_dims: List[int] = [64, 32],\n",
    "        latent_dim: int = 16,\n",
    "        activation_type: str = \"ReLU\",\n",
    "        output_activation_type: Optional[str] = None,\n",
    "    ) -> None:\n",
    "        super(BatchNormAutoencoder, self).__init__()\n",
    "\n",
    "        # Select activation function\n",
    "        activation: nn.Module\n",
    "        if activation_type == \"ReLU\":\n",
    "            activation = nn.ReLU()\n",
    "        elif activation_type == \"LeakyReLU\":\n",
    "            activation = nn.LeakyReLU()\n",
    "        elif activation_type == \"ELU\":\n",
    "            activation = nn.ELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unknown activation type provided\")\n",
    "\n",
    "        # Build encoder\n",
    "        encoder_layers: List[nn.Module] = []\n",
    "        current_dim: int = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            encoder_layers.append(nn.Linear(current_dim, h_dim))\n",
    "            encoder_layers.append(nn.BatchNorm1d(h_dim))\n",
    "            encoder_layers.append(activation)\n",
    "            current_dim = h_dim\n",
    "\n",
    "        # Latent layer\n",
    "        encoder_layers.append(nn.Linear(current_dim, latent_dim))\n",
    "        self.encoder: nn.Sequential = nn.Sequential(*encoder_layers)\n",
    "\n",
    "        # Select output activation function\n",
    "        output_activation: Optional[nn.Module] = None\n",
    "        if output_activation_type == \"ReLU\":\n",
    "            output_activation = nn.ReLU()\n",
    "        elif output_activation_type == \"LeakyReLU\":\n",
    "            output_activation = nn.LeakyReLU()\n",
    "        elif output_activation_type == \"ELU\":\n",
    "            output_activation = nn.ELU()\n",
    "        elif output_activation_type == \"Sigmoid\":\n",
    "            output_activation = nn.Sigmoid()\n",
    "        elif output_activation_type == \"Tanh\":\n",
    "            output_activation = nn.Tanh()\n",
    "        elif output_activation_type is None:\n",
    "            output_activation = None\n",
    "        else:\n",
    "            raise ValueError(\"Unknown activation type provided\")\n",
    "\n",
    "        # Build decoder\n",
    "        decoder_layers: List[nn.Module] = []\n",
    "        current_dim = latent_dim\n",
    "        for h_dim in reversed(hidden_dims):\n",
    "            decoder_layers.append(nn.Linear(current_dim, h_dim))\n",
    "            decoder_layers.append(nn.BatchNorm1d(h_dim))\n",
    "            decoder_layers.append(activation)\n",
    "            current_dim = h_dim\n",
    "\n",
    "        # Add final output layer (no batch norm on output layer)\n",
    "        decoder_layers.append(nn.Linear(current_dim, input_dim))\n",
    "\n",
    "        # Add output activation if specified\n",
    "        if output_activation is not None:\n",
    "            decoder_layers.append(output_activation)\n",
    "\n",
    "        self.decoder: nn.Sequential = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        encoded: torch.Tensor = self.encoder(x)\n",
    "        decoded: torch.Tensor = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_existing_model:\n",
    "    autoencoder = BatchNormAutoencoder(\n",
    "        input_dim=existing_model_architecture[\"input_dim\"],\n",
    "        hidden_dims=existing_model_architecture[\"hidden_dims\"],\n",
    "        latent_dim=existing_model_architecture[\"latent_dim\"],\n",
    "        activation_type=existing_model_architecture[\"activation_type\"],\n",
    "        output_activation_type=existing_model_architecture[\"output_activation_type\"],\n",
    "    )\n",
    "else:\n",
    "    # Create model\n",
    "    autoencoder = BatchNormAutoencoder(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dims=new_model_architecture[\"hidden_dims\"],\n",
    "        latent_dim=new_model_architecture[\"latent_dim\"],\n",
    "        activation_type=new_model_architecture[\"activation_type\"],\n",
    "        output_activation_type=new_model_architecture[\"output_activation_type\"],\n",
    "    )\n",
    "\n",
    "    # loss and optimizer\n",
    "    optimizer = optim.Adam(\n",
    "        autoencoder.parameters(), lr=new_model_learning_parameters[\"lr\"]\n",
    "    )\n",
    "    criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=new_model_learning_parameters[\"batch_size\"],\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=new_model_learning_parameters[\"batch_size\"],\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_autoencoder(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    val_loader: DataLoader = None,\n",
    "    epochs: int = 10,\n",
    "    best_model_path: str = \"./best_autoencoder_tuning.pth\",\n",
    "    verbose: bool = False,\n",
    "    early_stopping_patience: int = 5,\n",
    "    improvement_threshold: float = 0.001,  # Minimum improvement to be considered significant\n",
    "    good_model_threshold: float = 0.05,  # Threshold for considering a model \"good\"\n",
    "    plot_results: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train an autoencoder model with early stopping and model saving capabilities.\n",
    "\n",
    "    This function handles the complete training workflow for an autoencoder, including:\n",
    "    - Forward/backward passes and optimization\n",
    "    - Loss tracking for training and validation\n",
    "    - Early stopping when improvement plateaus\n",
    "    - Saving the best model based on validation or training loss\n",
    "    - Optional progress reporting and loss curve plotting\n",
    "    - Model quality assessment based on final reconstruction loss\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        The autoencoder model to train\n",
    "    train_loader : DataLoader\n",
    "        PyTorch DataLoader for training data\n",
    "    optimizer : optim.Optimizer\n",
    "        PyTorch optimizer for model parameter updates\n",
    "    criterion : nn.Module\n",
    "        Loss function (typically MSELoss for autoencoders)\n",
    "    val_loader : DataLoader, optional\n",
    "        PyTorch DataLoader for validation data, by default None\n",
    "    epochs : int, optional\n",
    "        Maximum number of training epochs, by default 10\n",
    "    best_model_path : str, optional\n",
    "        Path to save the best model checkpoint, by default \"./best_autoencoder_tuning.pth\"\n",
    "    verbose : bool, optional\n",
    "        Whether to print training progress, by default False\n",
    "    early_stopping_patience : int, optional\n",
    "        Number of epochs with no improvement after which to stop training, by default 5\n",
    "    improvement_threshold : float, optional\n",
    "        Minimum improvement in loss to be considered significant, by default 0.001\n",
    "    good_model_threshold : float, optional\n",
    "        Maximum loss value for a model to be considered \"good\", by default 0.05\n",
    "    plot_results : bool, optional\n",
    "        Whether to plot loss curves after training, by default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (history, is_good_model) where:\n",
    "        - history: dict with loss values over epochs\n",
    "        - is_good_model: bool indicating if model meets quality threshold\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - When validation data is provided, early stopping is based on validation loss,\n",
    "      otherwise training loss is used\n",
    "    - The best model is loaded at the end of training\n",
    "    - If best_val_loss < good_model_threshold, the model is considered good\n",
    "    \"\"\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\")\n",
    "        print(f\"Using device: {device}\")\n",
    "        print(\"Training autoencoder...\")\n",
    "\n",
    "    history = {\"loss\": [], \"val_loss\": []}\n",
    "    model.train()\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        total_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch_x = batch[0].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_x)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        history[\"loss\"].append(avg_loss)\n",
    "\n",
    "        if val_loader is not None:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_batch in val_loader:\n",
    "                    val_inputs = val_batch[0].to(device)\n",
    "                    val_outputs = model(val_inputs)\n",
    "                    batch_val_loss = criterion(val_outputs, val_inputs).item()\n",
    "                    val_loss += batch_val_loss\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            history[\"val_loss\"].append(avg_val_loss)\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.10f}, Val Loss: {avg_val_loss:.10f}\"\n",
    "                )\n",
    "            # Save model if validation loss improved\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                improvement = best_val_loss - avg_val_loss\n",
    "\n",
    "                # Check if improvement is significant\n",
    "                if improvement > improvement_threshold:\n",
    "                    patience_counter = 0  # Reset patience counter\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                # Save the model\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"model_state_dict\": model.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                        \"val_loss\": best_val_loss,\n",
    "                    },\n",
    "                    best_model_path,\n",
    "                )\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"✅ Model saved with val_loss: {best_val_loss:.10f}\")\n",
    "\n",
    "                model.train()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"Early stopping triggered after {epoch+1} epochs due to lack of improvement.\"\n",
    "                    )\n",
    "                break\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.10f}\")\n",
    "\n",
    "            # If no validation set, save based on training loss\n",
    "            if avg_loss < best_val_loss:\n",
    "                improvement = best_val_loss - avg_loss\n",
    "\n",
    "                # Check if improvement is significant\n",
    "                if improvement > improvement_threshold:\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                best_val_loss = avg_loss\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"model_state_dict\": model.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                        \"train_loss\": best_val_loss,\n",
    "                    },\n",
    "                    best_model_path,\n",
    "                )\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"✅ Model saved with train_loss: {best_val_loss:.10f}\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            # Check early stopping conditions\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"Early stopping triggered after {epoch+1} epochs due to lack of improvement.\"\n",
    "                    )\n",
    "                break\n",
    "\n",
    "    if plot_results:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.plot(history[\"loss\"], label=\"Training Loss\")\n",
    "        if \"val_loss\" in history and history[\"val_loss\"]:\n",
    "            plt.plot(history[\"val_loss\"], label=\"Validation Loss\")\n",
    "        plt.title(f\"Loss History (Epoch {epoch+1})\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "        # Load best model\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        best_loss = checkpoint.get(\"val_loss\", checkpoint.get(\"train_loss\"))\n",
    "\n",
    "    if best_loss < good_model_threshold:\n",
    "        print(f\"Model is good with loss {best_loss}\")\n",
    "        is_good_model = True\n",
    "    else:\n",
    "        print(f\"Model is bad with loss {best_loss}\")\n",
    "        is_good_model = False\n",
    "\n",
    "    return history, is_good_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device: cpu\n",
      "Training autoencoder...\n",
      "Epoch 1/50, Train Loss: 0.2360623449, Val Loss: 0.2365447879\n",
      "✅ Model saved with val_loss: 0.2365447879\n",
      "Epoch 2/50, Train Loss: 0.1874300480, Val Loss: 0.2155820504\n",
      "✅ Model saved with val_loss: 0.2155820504\n",
      "Epoch 3/50, Train Loss: 0.1409711510, Val Loss: 0.1799286380\n",
      "✅ Model saved with val_loss: 0.1799286380\n",
      "Epoch 4/50, Train Loss: 0.1032067284, Val Loss: 0.1365063339\n",
      "✅ Model saved with val_loss: 0.1365063339\n",
      "Epoch 5/50, Train Loss: 0.0738685206, Val Loss: 0.1001007706\n",
      "✅ Model saved with val_loss: 0.1001007706\n",
      "Epoch 6/50, Train Loss: 0.0534784734, Val Loss: 0.0762121640\n",
      "✅ Model saved with val_loss: 0.0762121640\n",
      "Epoch 7/50, Train Loss: 0.0398948975, Val Loss: 0.0586739685\n",
      "✅ Model saved with val_loss: 0.0586739685\n",
      "Epoch 8/50, Train Loss: 0.0312613927, Val Loss: 0.0445429590\n",
      "✅ Model saved with val_loss: 0.0445429590\n",
      "Epoch 9/50, Train Loss: 0.0248324521, Val Loss: 0.0323171280\n",
      "✅ Model saved with val_loss: 0.0323171280\n",
      "Epoch 10/50, Train Loss: 0.0214128051, Val Loss: 0.0247893883\n",
      "✅ Model saved with val_loss: 0.0247893883\n",
      "Epoch 11/50, Train Loss: 0.0173214765, Val Loss: 0.0200011833\n",
      "✅ Model saved with val_loss: 0.0200011833\n",
      "Epoch 12/50, Train Loss: 0.0163146257, Val Loss: 0.0167394467\n",
      "✅ Model saved with val_loss: 0.0167394467\n",
      "Epoch 13/50, Train Loss: 0.0144233914, Val Loss: 0.0145681966\n",
      "✅ Model saved with val_loss: 0.0145681966\n",
      "Epoch 14/50, Train Loss: 0.0137116913, Val Loss: 0.0132272365\n",
      "✅ Model saved with val_loss: 0.0132272365\n",
      "Epoch 15/50, Train Loss: 0.0116746997, Val Loss: 0.0121821407\n",
      "✅ Model saved with val_loss: 0.0121821407\n",
      "Epoch 16/50, Train Loss: 0.0106894551, Val Loss: 0.0112820528\n",
      "✅ Model saved with val_loss: 0.0112820528\n",
      "Epoch 17/50, Train Loss: 0.0098096747, Val Loss: 0.0103625925\n",
      "✅ Model saved with val_loss: 0.0103625925\n",
      "Epoch 18/50, Train Loss: 0.0094017828, Val Loss: 0.0095052584\n",
      "✅ Model saved with val_loss: 0.0095052584\n",
      "Epoch 19/50, Train Loss: 0.0091242503, Val Loss: 0.0089357845\n",
      "✅ Model saved with val_loss: 0.0089357845\n",
      "Epoch 20/50, Train Loss: 0.0090581936, Val Loss: 0.0083097173\n",
      "✅ Model saved with val_loss: 0.0083097173\n",
      "Epoch 21/50, Train Loss: 0.0078705140, Val Loss: 0.0079046448\n",
      "✅ Model saved with val_loss: 0.0079046448\n",
      "Epoch 22/50, Train Loss: 0.0078254494, Val Loss: 0.0073956186\n",
      "✅ Model saved with val_loss: 0.0073956186\n",
      "Epoch 23/50, Train Loss: 0.0075513696, Val Loss: 0.0070512872\n",
      "✅ Model saved with val_loss: 0.0070512872\n",
      "Epoch 24/50, Train Loss: 0.0075476647, Val Loss: 0.0067611251\n",
      "✅ Model saved with val_loss: 0.0067611251\n",
      "Epoch 25/50, Train Loss: 0.0068493730, Val Loss: 0.0064397133\n",
      "✅ Model saved with val_loss: 0.0064397133\n",
      "Epoch 26/50, Train Loss: 0.0070044046, Val Loss: 0.0061449551\n",
      "✅ Model saved with val_loss: 0.0061449551\n",
      "Epoch 27/50, Train Loss: 0.0067023317, Val Loss: 0.0059542896\n",
      "✅ Model saved with val_loss: 0.0059542896\n",
      "Epoch 28/50, Train Loss: 0.0063289146, Val Loss: 0.0058682205\n",
      "✅ Model saved with val_loss: 0.0058682205\n",
      "Epoch 29/50, Train Loss: 0.0059316537, Val Loss: 0.0056657079\n",
      "✅ Model saved with val_loss: 0.0056657079\n",
      "Epoch 30/50, Train Loss: 0.0065037914, Val Loss: 0.0055002228\n",
      "✅ Model saved with val_loss: 0.0055002228\n",
      "Epoch 31/50, Train Loss: 0.0061117475, Val Loss: 0.0053173224\n",
      "✅ Model saved with val_loss: 0.0053173224\n",
      "Epoch 32/50, Train Loss: 0.0054352814, Val Loss: 0.0050860096\n",
      "✅ Model saved with val_loss: 0.0050860096\n",
      "Epoch 33/50, Train Loss: 0.0053712212, Val Loss: 0.0049221914\n",
      "✅ Model saved with val_loss: 0.0049221914\n",
      "Epoch 34/50, Train Loss: 0.0050391663, Val Loss: 0.0048126159\n",
      "✅ Model saved with val_loss: 0.0048126159\n",
      "Epoch 35/50, Train Loss: 0.0047907752, Val Loss: 0.0045622417\n",
      "✅ Model saved with val_loss: 0.0045622417\n",
      "Epoch 36/50, Train Loss: 0.0058138987, Val Loss: 0.0044060301\n",
      "✅ Model saved with val_loss: 0.0044060301\n",
      "Epoch 37/50, Train Loss: 0.0046613595, Val Loss: 0.0042768826\n",
      "✅ Model saved with val_loss: 0.0042768826\n",
      "Epoch 38/50, Train Loss: 0.0050330522, Val Loss: 0.0040997930\n",
      "✅ Model saved with val_loss: 0.0040997930\n",
      "Epoch 39/50, Train Loss: 0.0050654432, Val Loss: 0.0040327227\n",
      "✅ Model saved with val_loss: 0.0040327227\n",
      "Epoch 40/50, Train Loss: 0.0046106072, Val Loss: 0.0039060870\n",
      "✅ Model saved with val_loss: 0.0039060870\n",
      "Epoch 41/50, Train Loss: 0.0047778300, Val Loss: 0.0037766073\n",
      "✅ Model saved with val_loss: 0.0037766073\n",
      "Epoch 42/50, Train Loss: 0.0047102216, Val Loss: 0.0037341329\n",
      "✅ Model saved with val_loss: 0.0037341329\n",
      "Epoch 43/50, Train Loss: 0.0040280831, Val Loss: 0.0035637774\n",
      "✅ Model saved with val_loss: 0.0035637774\n",
      "Epoch 44/50, Train Loss: 0.0038608902, Val Loss: 0.0035084984\n",
      "✅ Model saved with val_loss: 0.0035084984\n",
      "Epoch 45/50, Train Loss: 0.0041738248, Val Loss: 0.0035033213\n",
      "✅ Model saved with val_loss: 0.0035033213\n",
      "Epoch 46/50, Train Loss: 0.0041032103, Val Loss: 0.0035412909\n",
      "Epoch 47/50, Train Loss: 0.0035335920, Val Loss: 0.0024320359\n",
      "✅ Model saved with val_loss: 0.0024320359\n",
      "Epoch 48/50, Train Loss: 0.0038936025, Val Loss: 0.0024749805\n",
      "Epoch 49/50, Train Loss: 0.0026077250, Val Loss: 0.0020988932\n",
      "✅ Model saved with val_loss: 0.0020988932\n",
      "Epoch 50/50, Train Loss: 0.0041067164, Val Loss: 0.0023514110\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is bad with loss 0.0020988932228647172\n"
     ]
    }
   ],
   "source": [
    "if not use_existing_model:\n",
    "    history, is_good_model = train_autoencoder(\n",
    "        model=autoencoder,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        epochs=new_model_learning_parameters[\"epochs\"],\n",
    "        best_model_path=best_model_path,\n",
    "        verbose=True,\n",
    "        early_stopping_patience=new_model_learning_parameters[\n",
    "            \"early_stopping_patience\"\n",
    "        ],\n",
    "        improvement_threshold=new_model_learning_parameters[\"improvement_threshold\"],\n",
    "        good_model_threshold=new_model_learning_parameters[\"good_model_threshold\"],\n",
    "        plot_results=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch model saved at: best_models/best_model_proposed.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"Pytorch model saved at:\", best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNormAutoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=122, out_features=116, bias=True)\n",
       "    (1): BatchNorm1d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Linear(in_features=116, out_features=96, bias=True)\n",
       "    (4): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=96, out_features=64, bias=True)\n",
       "    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "    (9): Linear(in_features=64, out_features=48, bias=True)\n",
       "    (10): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.01)\n",
       "    (12): Linear(in_features=48, out_features=22, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=22, out_features=48, bias=True)\n",
       "    (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Linear(in_features=48, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=64, out_features=96, bias=True)\n",
       "    (7): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "    (9): Linear(in_features=96, out_features=116, bias=True)\n",
       "    (10): BatchNorm1d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.01)\n",
       "    (12): Linear(in_features=116, out_features=122, bias=True)\n",
       "    (13): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best model\n",
    "if use_existing_model:\n",
    "    checkpoint = torch.load(existing_model_path)\n",
    "    autoencoder.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "else:\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    autoencoder.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "autoencoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to ONNX format: saved_models/autoencoder.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "if export_model and not use_existing_model:\n",
    "    # Prepare a sample input tensor with the correct shape\n",
    "    dummy_input = torch.randn(1, input_dim, device=device)\n",
    "\n",
    "    torch.onnx.export(\n",
    "        autoencoder,  # model being run\n",
    "        dummy_input,  # model input\n",
    "        onnx_path,  # where to save the model\n",
    "        export_params=True,  # store trained parameters inside model file\n",
    "        opset_version=17,  # ONNX version\n",
    "        do_constant_folding=True,  # optimize constant folding\n",
    "        input_names=[\"input\"],  # model's input names\n",
    "        output_names=[\"output\"],  # model's output names\n",
    "        dynamic_axes={\n",
    "            \"input\": {0: \"batch_size\"},  # variable length axes\n",
    "            \"output\": {0: \"batch_size\"},\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"Model exported to ONNX format: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dbscan tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# extract encoded features\n",
    "X_train_full_tensor = torch.FloatTensor(X_train_full)\n",
    "X_train_full_dataset = TensorDataset(X_train_full_tensor)\n",
    "X_train_full_loader = DataLoader(X_train_full_dataset, batch_size=256)\n",
    "\n",
    "# Extract in batches to prevent memory issues\n",
    "if use_full_train_set:\n",
    "    X_encoded = []\n",
    "    with torch.no_grad():\n",
    "        for data in X_train_full_loader:\n",
    "            data_x = data[0].to(device)\n",
    "            encoded = autoencoder.encode(data_x)\n",
    "            X_encoded.append(encoded.cpu().numpy())\n",
    "    X_encoded = np.vstack(X_encoded)\n",
    "else:\n",
    "    X_encoded = []\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            data_x = data[0].to(device)\n",
    "            encoded = autoencoder.encode(data_x)\n",
    "            X_encoded.append(encoded.cpu().numpy())\n",
    "    X_encoded = np.vstack(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_eps_range_with_elbow_method(X, k=20, multiplier=(0.5, 2.0), plot=True):\n",
    "    \"\"\"\n",
    "    Find a suitable eps range for DBSCAN using the elbow method.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like\n",
    "        The encoded data points\n",
    "    k : int, default=20\n",
    "        Number of neighbors to consider (corresponds to min_samples)\n",
    "    multiplier : tuple, default=(0.5, 2.0)\n",
    "        Factors to multiply the elbow point by to create a range\n",
    "    plot : bool, default=True\n",
    "        Whether to show the k-distance plot\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (min_eps, max_eps) suitable range for eps parameter\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate distances to k nearest neighbors for each point\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, metric=\"manhattan\").fit(X)\n",
    "    distances, _ = nbrs.kneighbors(X)\n",
    "\n",
    "    # Sort the distances to the kth neighbor in ascending order\n",
    "    k_distances = np.sort(distances[:, -1])\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(k_distances)\n",
    "        plt.xlabel(\"Points (sorted)\")\n",
    "        plt.ylabel(f\"Distance to {k}th nearest neighbor\")\n",
    "        plt.title(\"K-distance Plot for DBSCAN eps Selection\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # Add horizontal lines at suggested eps range\n",
    "        # This will be calculated below\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Find the elbow point (simple method - you might want a more sophisticated approach)\n",
    "    # Look for maximum curvature in the sorted distance plot\n",
    "    n_points = len(k_distances)\n",
    "    all_coords = np.vstack((range(n_points), k_distances)).T\n",
    "\n",
    "    # Compute point-to-line distances for all points\n",
    "    line_vec = all_coords[-1] - all_coords[0]\n",
    "    line_vec_norm = line_vec / np.sqrt(np.sum(line_vec**2))\n",
    "    vec_from_first = all_coords - all_coords[0]\n",
    "    scalar_prod = np.sum(vec_from_first * np.tile(line_vec_norm, (n_points, 1)), axis=1)\n",
    "    vec_to_line = vec_from_first - np.outer(scalar_prod, line_vec_norm)\n",
    "    dist_to_line = np.sqrt(np.sum(vec_to_line**2, axis=1))\n",
    "\n",
    "    # Elbow point is the point with max distance to the line\n",
    "    elbow_idx = np.argmax(dist_to_line)\n",
    "    elbow_eps = k_distances[elbow_idx]\n",
    "\n",
    "    # Create a range around the elbow point\n",
    "    min_eps = elbow_eps * multiplier[0]\n",
    "    max_eps = elbow_eps * multiplier[1]\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(k_distances)\n",
    "        plt.axhline(\n",
    "            y=min_eps,\n",
    "            color=\"r\",\n",
    "            linestyle=\"--\",\n",
    "            alpha=0.7,\n",
    "            label=f\"Min eps: {min_eps:.2f}\",\n",
    "        )\n",
    "        plt.axhline(\n",
    "            y=elbow_eps,\n",
    "            color=\"g\",\n",
    "            linestyle=\"-\",\n",
    "            alpha=0.7,\n",
    "            label=f\"Elbow eps: {elbow_eps:.2f}\",\n",
    "        )\n",
    "        plt.axhline(\n",
    "            y=max_eps,\n",
    "            color=\"r\",\n",
    "            linestyle=\"--\",\n",
    "            alpha=0.7,\n",
    "            label=f\"Max eps: {max_eps:.2f}\",\n",
    "        )\n",
    "        plt.axvline(x=elbow_idx, color=\"g\", linestyle=\":\", alpha=0.5)\n",
    "        plt.xlabel(\"Points (sorted)\")\n",
    "        plt.ylabel(f\"Distance to {k}th nearest neighbor\")\n",
    "        plt.title(\"K-distance Plot with Suggested eps Range\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    return min_eps, max_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(3.381192207336426), np.float64(13.524768829345703))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim_encoded = X_encoded.shape[1]\n",
    "\n",
    "k_for_elbow = int((20 + input_dim_encoded * 2) / 2)\n",
    "min_eps, max_eps = find_eps_range_with_elbow_method(\n",
    "    X_encoded,\n",
    "    k=k_for_elbow,\n",
    "    plot=False,\n",
    ")\n",
    "min_eps, max_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_dbscan(\n",
    "    trial: optuna.Trial,\n",
    "    X_encoded: np.ndarray,\n",
    "    evaluation_metric: str = \"silhouette\",\n",
    "    eps_range: tuple[float, float] = (0.1, 15.0),\n",
    "    min_samples_range: tuple[int, int] = (20, 50),\n",
    "    distance_metric: str = \"euclidean\",  # \"manhattan\", \"cosine\"\n",
    "    n_jobs: int = -1,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Inner objective function for optimizing DBSCAN clustering hyperparameters.\n",
    "\n",
    "    This function is used by Optuna for hyperparameter optimization of a DBSCAN model.\n",
    "    It evaluates different clustering configurations using the specified evaluation metric.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial : optuna.Trial\n",
    "        Optuna trial object used for hyperparameter suggestion\n",
    "    X_encoded : np.ndarray\n",
    "        Array of encoded data points to cluster\n",
    "    evaluation_metric : str, default=\"silhouette\"\n",
    "        Metric to evaluate cluster quality: \"silhouette\", \"davies_bouldin\", or \"calinski_harabasz\"\n",
    "    eps_range : tuple[float, float], default=(0.1, 15.0)\n",
    "        Range (min, max) for the eps parameter of DBSCAN\n",
    "    min_samples_range : tuple[int, int], default=(20, 50)\n",
    "        Range (min, max) for the min_samples parameter of DBSCAN\n",
    "    metric : str, default=\"euclidean\"\n",
    "        Distance metric for DBSCAN\n",
    "    score_threshold : float, default=0.60\n",
    "        Minimum score threshold to consider a clustering configuration valid\n",
    "    n_jobs : int, default=-1\n",
    "        Number of parallel jobs to run for DBSCAN\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Clustering quality score (higher is better) unless evaluation_metric is \"davies_bouldin\"\n",
    "        Returns -inf for invalid clustering configurations\n",
    "    \"\"\"\n",
    "\n",
    "    def get_score(X, labels, metric_name, mask=None):\n",
    "        if mask is not None:\n",
    "            X = X[mask]\n",
    "            labels = labels[mask]\n",
    "\n",
    "        if metric_name == \"silhouette\":\n",
    "            return silhouette_score(X, labels)\n",
    "        elif metric_name == \"davies_bouldin\":\n",
    "            return -davies_bouldin_score(\n",
    "                X, labels\n",
    "            )  # Negative because we want to maximize\n",
    "        elif metric_name == \"calinski_harabasz\":\n",
    "            return calinski_harabasz_score(X, labels)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {metric_name}\")\n",
    "\n",
    "    eps = trial.suggest_float(\"eps\", eps_range[0], eps_range[1])\n",
    "    min_samples = trial.suggest_int(\n",
    "        \"min_samples\", min_samples_range[0], min_samples_range[1]\n",
    "    )\n",
    "\n",
    "    dbscan = DBSCAN(\n",
    "        eps=eps, min_samples=min_samples, metric=distance_metric, n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    cluster_labels = dbscan.fit_predict(X_encoded)\n",
    "\n",
    "    # Calculate the number of clusters (excluding noise points)\n",
    "    unique_clusters = set(cluster_labels)\n",
    "    n_clusters = len(unique_clusters) - (1 if -1 in unique_clusters else 0)\n",
    "\n",
    "    # Set custom attribute for number of clusters\n",
    "    trial.set_user_attr(\"n_clusters\", n_clusters)\n",
    "\n",
    "    # Set custom attribute for cluster data points\n",
    "    cluster_data_points = {}\n",
    "    for cluster_id in unique_clusters:\n",
    "        # Store indices of points in each cluster\n",
    "        cluster_indices = np.where(cluster_labels == cluster_id)[0].tolist()\n",
    "        cluster_data_points[int(cluster_id)] = len(cluster_indices)\n",
    "    trial.set_user_attr(\"cluster_data_points\", cluster_data_points)\n",
    "\n",
    "    if n_clusters < 2:\n",
    "        print(\"not enough clusters\")\n",
    "        return -float(\"inf\")  # Penalize solutions with too few clusters\n",
    "\n",
    "    # For silhouette score, we need to exclude noise points (-1)\n",
    "    if evaluation_metric == \"silhouette\":\n",
    "        mask = cluster_labels != -1\n",
    "        if sum(mask) < 2:\n",
    "            print(\"not enough points in clusters\")\n",
    "            return -float(\"inf\")\n",
    "        score = get_score(X_encoded, cluster_labels, evaluation_metric, mask)\n",
    "    else:\n",
    "        score = get_score(X_encoded, cluster_labels, evaluation_metric)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-07 02:48:21,153] A new study created in memory with name: no-name-4e2edb69-c4fe-48df-8e82-c04c122d8d93\n",
      "[I 2025-03-07 02:48:21,235] Trial 0 finished with value: 0.4842154085636139 and parameters: {'eps': 6.871603027419332, 'min_samples': 27}. Best is trial 0 with value: 0.4842154085636139.\n",
      "[I 2025-03-07 02:48:21,319] Trial 1 finished with value: 0.5935849547386169 and parameters: {'eps': 4.58433142702699, 'min_samples': 12}. Best is trial 1 with value: 0.5935849547386169.\n",
      "[I 2025-03-07 02:48:21,392] Trial 2 finished with value: 0.5916091799736023 and parameters: {'eps': 5.126327406968786, 'min_samples': 7}. Best is trial 1 with value: 0.5935849547386169.\n",
      "[I 2025-03-07 02:48:21,468] Trial 3 finished with value: 0.35603421926498413 and parameters: {'eps': 6.991612085238597, 'min_samples': 6}. Best is trial 1 with value: 0.5935849547386169.\n",
      "[I 2025-03-07 02:48:21,533] Trial 4 finished with value: 0.5856406688690186 and parameters: {'eps': 5.429667012281406, 'min_samples': 8}. Best is trial 1 with value: 0.5935849547386169.\n",
      "[I 2025-03-07 02:48:21,657] Trial 5 finished with value: 0.6052386164665222 and parameters: {'eps': 4.948898414372888, 'min_samples': 18}. Best is trial 5 with value: 0.6052386164665222.\n",
      "[I 2025-03-07 02:48:21,741] Trial 6 finished with value: -inf and parameters: {'eps': 11.119131831865044, 'min_samples': 28}. Best is trial 5 with value: 0.6052386164665222.\n",
      "[I 2025-03-07 02:48:21,768] Trial 7 finished with value: -inf and parameters: {'eps': 12.061046011472012, 'min_samples': 19}. Best is trial 5 with value: 0.6052386164665222.\n",
      "[I 2025-03-07 02:48:21,812] Trial 8 finished with value: 0.5922170877456665 and parameters: {'eps': 3.7794574661374694, 'min_samples': 29}. Best is trial 5 with value: 0.6052386164665222.\n",
      "[I 2025-03-07 02:48:21,907] Trial 9 finished with value: 0.3870580494403839 and parameters: {'eps': 9.662201123209364, 'min_samples': 31}. Best is trial 5 with value: 0.6052386164665222.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough clusters\n",
      "not enough clusters\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "dbscan_objective_lambda = lambda trial: objective_dbscan(\n",
    "    trial,\n",
    "    X_encoded=X_encoded,\n",
    "    evaluation_metric=dbscan_tuning_parameters[\"evaluation_metric\"],\n",
    "    eps_range=(min_eps, max_eps),\n",
    "    min_samples_range=(1, input_dim_encoded * 2),\n",
    "    distance_metric=dbscan_tuning_parameters[\"distance_metric\"],\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "if with_storage_dbscan:\n",
    "    dbscan_study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        storage=dbscan_optuna_storage_path,\n",
    "        study_name=\"dbscan_study\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    dbscan_study.optimize(\n",
    "        dbscan_objective_lambda,\n",
    "        n_trials=dbscan_tuning_parameters[\"trials\"],\n",
    "    )\n",
    "else:\n",
    "    dbscan_study = optuna.create_study(direction=\"maximize\")\n",
    "    dbscan_study.optimize(\n",
    "        dbscan_objective_lambda,\n",
    "        n_trials=dbscan_tuning_parameters[\"trials\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 4.948898414372888\n",
      "min_samples = 18\n",
      "n_clusters = 6\n",
      "cluster_data_points\n",
      "{-1: 89, 0: 82, 1: 325, 2: 85, 3: 33, 4: 36, 5: 23}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# get dbscan best parameters\n",
    "eps = dbscan_study.best_params[\"eps\"]\n",
    "min_samples = dbscan_study.best_params[\"min_samples\"]\n",
    "\n",
    "# get dbscan best trial\n",
    "best_trial_dbscan = dbscan_study.best_trial\n",
    "best_trial_dbscan_user_attrs = best_trial_dbscan.user_attrs\n",
    "\n",
    "n_clusters = best_trial_dbscan_user_attrs[\"n_clusters\"]\n",
    "cluster_data_points = best_trial_dbscan_user_attrs[\"cluster_data_points\"]\n",
    "\n",
    "print(f\"eps = {eps}\")\n",
    "print(f\"min_samples = {min_samples}\")\n",
    "print(f\"n_clusters = {n_clusters}\")\n",
    "print(\"cluster_data_points\")\n",
    "pprint.pprint(cluster_data_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit the DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBOCSVM_V2:\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel=\"rbf\",\n",
    "        gamma=\"scale\",\n",
    "        nu=0.5,\n",
    "        eps=0.5,\n",
    "        min_samples=10,\n",
    "        tree_metric=\"euclidean\",\n",
    "        dbscan_metric=\"euclidean\",\n",
    "        algorithm=\"kd_tree\",  # or 'ball_tree'\n",
    "        n_jobs=-1,  # Add n_jobs parameter\n",
    "    ):\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.nu = nu\n",
    "        self.algorithm = algorithm\n",
    "        self.tree_metric = tree_metric\n",
    "        self.dbscan_metric = dbscan_metric\n",
    "        self.dbscan = DBSCAN(\n",
    "            eps=eps, min_samples=min_samples, n_jobs=n_jobs, metric=dbscan_metric\n",
    "        )  # Make it so that it can accept a metric parameter\n",
    "        self.svms = {}  # One SVM per cluster\n",
    "        self.dbscan_centroids = {}  # To store cluster centroids\n",
    "        self.cluster_points = {}  # Store points in each cluster\n",
    "        self.tree = None\n",
    "        # These attributes are mainly used for inspection purposes\n",
    "        self.cluster_sizes = {}  # Number of points in each cluster\n",
    "        self.n_jobs = n_jobs  # Store n_jobs\n",
    "        self.cluster_labels = None\n",
    "        self.unique_clusters = None\n",
    "\n",
    "    def fit_cluster(\n",
    "        self,\n",
    "        X,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Training data\n",
    "        \"\"\"\n",
    "\n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "        \"\"\"\n",
    "        NOTE: Current DBSCAN only uses euclidean distance, so the metric parameter is not used\n",
    "        TODO: Add metric parameter to DBSCAN to handle different distance metrics\n",
    "        'euclidean': Standard Euclidean distance. This is the default metric.\n",
    "        'manhattan': Manhattan or L1 distance (sum of absolute differences).\n",
    "        'chebyshev': Chebyshev or maximum distance.\n",
    "        'minkowski': Minkowski distance, a generalization of Euclidean and Manhattan distance. The power parameter p of the Minkowski metric can be controlled by the p parameter of DBSCAN.\n",
    "        'wminkowski': Weighted Minkowski distance.\n",
    "        'seuclidean': Standardized Euclidean distance.\n",
    "        'mahalanobis': Mahalanobis distance.\n",
    "        \"\"\"\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Fitting DBSCAN...\")\n",
    "        # NOTE: we use the dbscan that was initialized in the constructor\n",
    "        self.cluster_labels = self.dbscan.fit_predict(X)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"DBSCAN Fitted...\")\n",
    "\n",
    "        self.unique_clusters = np.unique(self.cluster_labels)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Unique Clusters: {self.unique_clusters}\")\n",
    "\n",
    "        for cluster in self.unique_clusters:\n",
    "            n_points = np.sum(self.cluster_labels == cluster)\n",
    "            self.cluster_sizes[int(cluster)] = int(n_points)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Cluster Sizes: {self.cluster_sizes}\")\n",
    "\n",
    "    def fit_ocsvm(\n",
    "        self,\n",
    "        X,\n",
    "        parameter_list=None,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Training data\n",
    "        parameter_list: dictionary of dictionaries\n",
    "            Each key in the dictionary is the cluster number and\n",
    "            the value is a dictionary containing the parameters for OCSVM\n",
    "            each dictionary looks like this:\n",
    "            {\n",
    "                0 : {\n",
    "                kernel: rbf, linear, poly, or sigmoid,\n",
    "                gamma: 'scale', 'auto' or a float,\n",
    "                nu: a float between 0 and 1 e.g 0.2,\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "        if parameter_list is None:\n",
    "            raise ValueError(\"parameter_list cannot be None\")\n",
    "\n",
    "        if len(parameter_list) < len(self.unique_clusters) - 1:\n",
    "            raise ValueError(\n",
    "                \"Number of parameters should be equal or greater than the number of clusters\"\n",
    "            )\n",
    "\n",
    "        def filter_dict(original_dict, keys_to_keep):\n",
    "            return {k: original_dict[k] for k in keys_to_keep if k in original_dict}\n",
    "\n",
    "        if len(parameter_list) >= len(self.unique_clusters) - 1:\n",
    "            cluster_count = list(self.cluster_sizes.keys())\n",
    "            if -1 in cluster_count:\n",
    "                cluster_count.remove(-1)\n",
    "            cluster_count\n",
    "\n",
    "            parameter_list = filter_dict(parameter_list, cluster_count)\n",
    "\n",
    "        for cluster in self.unique_clusters:\n",
    "\n",
    "            if cluster == -1:  # Skip noise cluster for SVM training\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Training for cluster {cluster} with {self.cluster_sizes[cluster]} points\"\n",
    "                )\n",
    "\n",
    "            # Boolean masking to get points in the current cluster\n",
    "            points = X[self.cluster_labels == cluster]\n",
    "            self.cluster_points[cluster] = points\n",
    "\n",
    "            if len(points) > 0:\n",
    "                # use parameters defined in constructor if not provided\n",
    "                if parameter_list is None:\n",
    "                    ocsvm = OneClassSVM(\n",
    "                        kernel=self.kernel,\n",
    "                        nu=self.nu,\n",
    "                        gamma=self.gamma,\n",
    "                    )\n",
    "                else:\n",
    "                    ocsvm = OneClassSVM(\n",
    "                        kernel=parameter_list[cluster][\"kernel\"],\n",
    "                        nu=parameter_list[cluster][\"nu\"],\n",
    "                        gamma=parameter_list[cluster][\"gamma\"],\n",
    "                    )\n",
    "                    if verbose:\n",
    "                        print(\n",
    "                            f\"OCSVM for cluster {cluster} uses nu: {parameter_list[cluster]['nu']}, gamma: {parameter_list[cluster]['gamma']}, kernel: {parameter_list[cluster]['kernel']}\"\n",
    "                        )\n",
    "\n",
    "                ocsvm.fit(points)\n",
    "\n",
    "                self.svms[cluster] = ocsvm\n",
    "\n",
    "                \"\"\"\n",
    "                TODO: Explore other alternatives for centroid calculation\n",
    "                \"->\" means the following line might be a downside of the current approach.\n",
    "                \n",
    "                - Median: More robust to outliers than the mean (`np.median(points, axis=0)`).\n",
    "                    -> Less representative if data is asymmetric  \n",
    "                - Trimmed Mean: Removes extreme values before computing the mean (`scipy.stats.trim_mean`).\n",
    "                    ->   Requires choosing the trimming percentage\n",
    "                - Weighted Mean: Assigns importance to points based on reliability.  \n",
    "                    ->  Requires defining weights\n",
    "                - Geometric Median: Minimizes sum of distances to all points. More robust to outliers than the mean.\n",
    "                    -> computationally expensive (`scipy.spatial`)\n",
    "                - Distance Metrics: Use median for Manhattan distance and mean for Euclidean distance.\n",
    "                    -> Requires choosing the distance metric\n",
    "                    \n",
    "                \"\"\"\n",
    "                self.dbscan_centroids[cluster] = np.mean(points, axis=0)\n",
    "\n",
    "        # Build tree with cluster centroids\n",
    "        centroids = [self.dbscan_centroids[c] for c in self.dbscan_centroids if c != -1]\n",
    "        self.valid_clusters = list(self.dbscan_centroids.keys())\n",
    "        if len(centroids) > 0:\n",
    "            centroids = np.array(centroids)\n",
    "            if self.algorithm == \"kd_tree\":\n",
    "                self.tree = KDTree(centroids, metric=self.tree_metric)\n",
    "            elif self.algorithm == \"ball_tree\":\n",
    "                self.tree = BallTree(centroids, metric=self.tree_metric)\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X,\n",
    "        dbscan_evaluation_metric=\"silhouette\",  # only used for reruns\n",
    "        dbscan_rerun=False,  # only used for reruns\n",
    "        dbscan_rerun_trials=10,  # only used for reruns\n",
    "        parameter_list=None,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Training data\n",
    "        dbscan_evaluation_metric : str\n",
    "            Metric to optimize ('silhouette', 'davies_bouldin', or 'calinski_harabasz')\n",
    "        dbscan_rerun : bool\n",
    "            Whether to rerun DBSCAN after fitting the model with the best parameters\n",
    "        dbscan_rerun_trials : int\n",
    "            Number of reruns for DBSCAN after fitting the model with the best parameters\n",
    "        parameter_list: dictionary of dictionaries\n",
    "            Each key in the dictionary is the cluster number and\n",
    "            the value is a dictionary containing the parameters for OCSVM\n",
    "            each dictionary looks like this:\n",
    "            {\n",
    "                0 : {\n",
    "                kernel: rbf, linear, poly, or sigmoid,\n",
    "                gamma: 'scale', 'auto' or a float,\n",
    "                nu: a float between 0 and 1 e.g 0.2,\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "\n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "        \"\"\"\n",
    "        NOTE: Current DBSCAN only uses euclidean distance, so the metric parameter is not used\n",
    "        TODO: Add metric parameter to DBSCAN to handle different distance metrics\n",
    "        'euclidean': Standard Euclidean distance. This is the default metric.\n",
    "        'manhattan': Manhattan or L1 distance (sum of absolute differences).\n",
    "        'chebyshev': Chebyshev or maximum distance.\n",
    "        'minkowski': Minkowski distance, a generalization of Euclidean and Manhattan distance. The power parameter p of the Minkowski metric can be controlled by the p parameter of DBSCAN.\n",
    "        'wminkowski': Weighted Minkowski distance.\n",
    "        'seuclidean': Standardized Euclidean distance.\n",
    "        'mahalanobis': Mahalanobis distance.\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Fitting DBSCAN...\")\n",
    "        # NOTE: we use the dbscan that was initialized in the constructor\n",
    "        cluster_labels = self.dbscan.fit_predict(X)\n",
    "        if verbose:\n",
    "            print(\"DBSCAN Fitted...\")\n",
    "\n",
    "        if dbscan_rerun:\n",
    "            if verbose:\n",
    "                print(\"Rerunning DBSCAN...\")\n",
    "\n",
    "            if dbscan_evaluation_metric == \"silhouette\":\n",
    "                current_score = silhouette_score(X, cluster_labels)\n",
    "            elif dbscan_evaluation_metric == \"davies_bouldin\":\n",
    "                current_score = davies_bouldin_score(X, cluster_labels)\n",
    "            else:  # calinski_harabasz\n",
    "                current_score = calinski_harabasz_score(X, cluster_labels)\n",
    "\n",
    "            for i in range(dbscan_rerun_trials):\n",
    "                if verbose:\n",
    "                    print(f\"DBSCAN Rerun {i+1}...\")\n",
    "\n",
    "                new_cluster_labels = self.dbscan.fit_predict(X)\n",
    "\n",
    "                if dbscan_evaluation_metric == \"silhouette\":\n",
    "                    new_score = silhouette_score(X, new_cluster_labels)\n",
    "                    if new_score > current_score:\n",
    "                        cluster_labels = new_cluster_labels\n",
    "                        current_score = new_score\n",
    "                elif dbscan_evaluation_metric == \"davies_bouldin\":\n",
    "                    new_score = davies_bouldin_score(X, new_cluster_labels)\n",
    "                    if new_score < current_score:\n",
    "                        cluster_labels = new_cluster_labels\n",
    "                        current_score = new_score\n",
    "                else:  # calinski_harabasz\n",
    "                    new_score = calinski_harabasz_score(X, new_cluster_labels)\n",
    "                    if new_score > current_score:\n",
    "                        cluster_labels = new_cluster_labels\n",
    "                        current_score = new_score\n",
    "\n",
    "        unique_clusters = np.unique(cluster_labels)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Unique Clusters: {unique_clusters}\")\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "            # Store the number of points in the cluster\n",
    "            # mainly for inspection purposes\n",
    "            n_points = np.sum(cluster_labels == cluster)\n",
    "            self.cluster_sizes[int(cluster)] = int(n_points)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Cluster Sizes: {self.cluster_sizes}\")\n",
    "\n",
    "        if parameter_list is not None and (len(parameter_list)) < (\n",
    "            len(unique_clusters) - 1\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Number of parameters should be equal or greater than the number of clusters\"\n",
    "            )\n",
    "\n",
    "        def filter_dict(original_dict, keys_to_keep):\n",
    "            return {k: original_dict[k] for k in keys_to_keep if k in original_dict}\n",
    "\n",
    "        if parameter_list is not None and (len(parameter_list)) >= (\n",
    "            len(unique_clusters) - 1\n",
    "        ):\n",
    "            cluster_count = list(self.cluster_sizes.keys())\n",
    "            cluster_count.remove(-1)\n",
    "            cluster_count\n",
    "\n",
    "            parameter_list = filter_dict(parameter_list, cluster_count)\n",
    "\n",
    "        self.parameter_list = parameter_list\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "\n",
    "            # Store the number of points in the cluster\n",
    "            # n_points = np.sum(cluster_labels == cluster)\n",
    "            # self.cluster_sizes[int(cluster)] = int(n_points)\n",
    "\n",
    "            if cluster == -1:  # Skip noise cluster for SVM training\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Training for cluster {cluster} with {self.cluster_sizes[cluster]} points\"\n",
    "                )\n",
    "\n",
    "            # Boolean masking to get points in the current cluster\n",
    "            points = X[cluster_labels == cluster]\n",
    "            self.cluster_points[cluster] = points\n",
    "\n",
    "            if len(points) > 0:\n",
    "                # use parameters defined in constructor if not provided\n",
    "                if parameter_list is None:\n",
    "                    ocsvm = OneClassSVM(\n",
    "                        kernel=self.kernel,\n",
    "                        nu=self.nu,\n",
    "                        gamma=self.gamma,\n",
    "                        degree=self.degree,\n",
    "                        coef0=self.coef0,\n",
    "                        tol=self.tol,\n",
    "                        shrinking=self.shrinking,\n",
    "                        cache_size=self.cache_size,\n",
    "                        max_iter=self.max_iter,\n",
    "                    )\n",
    "                else:\n",
    "                    ocsvm = OneClassSVM(\n",
    "                        kernel=parameter_list[cluster][\"kernel\"],\n",
    "                        nu=parameter_list[cluster][\"nu\"],\n",
    "                        gamma=parameter_list[cluster][\"gamma\"],\n",
    "                        degree=self.degree,\n",
    "                        coef0=self.coef0,\n",
    "                        tol=self.tol,\n",
    "                        shrinking=self.shrinking,\n",
    "                        cache_size=self.cache_size,\n",
    "                        max_iter=self.max_iter,\n",
    "                    )\n",
    "                    if verbose:\n",
    "                        print(\n",
    "                            f\"OCSVM for cluster {cluster} uses nu: {parameter_list[cluster]['nu']}, gamma: {parameter_list[cluster]['gamma']}, kernel: {parameter_list[cluster]['kernel']}\"\n",
    "                        )\n",
    "                ocsvm.fit(points)\n",
    "\n",
    "                self.svms[cluster] = ocsvm\n",
    "\n",
    "                \"\"\"\n",
    "                TODO: Explore other alternatives for centroid calculation\n",
    "                \"->\" means the following line might be a downside of the current approach.\n",
    "                \n",
    "                - Median: More robust to outliers than the mean (`np.median(points, axis=0)`).\n",
    "                    -> Less representative if data is asymmetric  \n",
    "                - Trimmed Mean: Removes extreme values before computing the mean (`scipy.stats.trim_mean`).\n",
    "                    ->   Requires choosing the trimming percentage\n",
    "                - Weighted Mean: Assigns importance to points based on reliability.  \n",
    "                    ->  Requires defining weights\n",
    "                - Geometric Median: Minimizes sum of distances to all points. More robust to outliers than the mean.\n",
    "                    -> computationally expensive (`scipy.spatial`)\n",
    "                - Distance Metrics: Use median for Manhattan distance and mean for Euclidean distance.\n",
    "                    -> Requires choosing the distance metric\n",
    "                    \n",
    "                \"\"\"\n",
    "                self.dbscan_centroids[cluster] = np.mean(points, axis=0)\n",
    "\n",
    "        # Build tree with cluster centroids\n",
    "        centroids = [self.dbscan_centroids[c] for c in self.dbscan_centroids if c != -1]\n",
    "        self.valid_clusters = list(self.dbscan_centroids.keys())\n",
    "        if len(centroids) > 0:\n",
    "            centroids = np.array(centroids)\n",
    "            if self.algorithm == \"kd_tree\":\n",
    "                self.tree = KDTree(\n",
    "                    centroids, leaf_size=self.leaf_size, metric=self.tree_metric\n",
    "                )\n",
    "            elif self.algorithm == \"ball_tree\":\n",
    "                self.tree = BallTree(\n",
    "                    centroids, leaf_size=self.leaf_size, metric=self.tree_metric\n",
    "                )\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.ones(len(X))\n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "        if self.tree is None:\n",
    "            return -1 * np.ones(len(X))\n",
    "\n",
    "        # Find nearest centroid\n",
    "        dist, ind = self.tree.query(X, k=1)\n",
    "        nearest_clusters = [self.valid_clusters[i] for i in ind.flatten()]\n",
    "\n",
    "        for i, cluster in enumerate(nearest_clusters):\n",
    "            if cluster in self.svms:\n",
    "                predictions[i] = self.svms[cluster].predict([X[i]])[0]\n",
    "            else:\n",
    "                predictions[i] = -1  # Anomaly if no SVM for cluster\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DB-OC-SVM model with default ocsvm parameters\n",
    "dbocsvm = DBOCSVM_V2(\n",
    "    kernel=\"rbf\",\n",
    "    gamma=\"auto\",\n",
    "    nu=0.2,\n",
    "    eps=eps,\n",
    "    min_samples=min_samples,\n",
    "    dbscan_metric=dbscan_tuning_parameters[\"distance_metric\"],\n",
    "    algorithm=dbocsvm_tree_algorithm,  # ball_tree, kd_tree,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting DBSCAN...\n",
      "DBSCAN Fitted...\n",
      "Unique Clusters: [-1  0  1  2  3  4  5]\n",
      "Cluster Sizes: {-1: 89, 0: 82, 1: 325, 2: 85, 3: 33, 4: 36, 5: 23}\n"
     ]
    }
   ],
   "source": [
    "dbocsvm.fit_cluster(X_encoded, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22543, 125)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>attack_binary</th>\n",
       "      <th>attack_categorical</th>\n",
       "      <th>attack_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>neptune</td>\n",
       "      <td>DoS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0       0.0        0.0        0.0   0.0             0.0     0.0  0.0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_RSTR  flag_S0  \\\n",
       "0                0.0        0.0              0.0  ...        0.0      0.0   \n",
       "\n",
       "   flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  attack_binary  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0             -1   \n",
       "\n",
       "   attack_categorical  attack_class  \n",
       "0             neptune           DoS  \n",
       "\n",
       "[1 rows x 125 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_set_path)\n",
    "print(test_df.shape)\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22543, 122) (22543,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into X and y\n",
    "X_test = test_df.drop(\n",
    "    columns=[\"attack_binary\", \"attack_categorical\", \"attack_class\"]\n",
    ").values\n",
    "y_test = test_df[\"attack_binary\"].values\n",
    "y_test_class = test_df[\"attack_class\"]\n",
    "\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract features from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22543, 22)\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.zeros(len(X_test_tensor)))\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "X_test_encoded = []\n",
    "with torch.no_grad():\n",
    "    for data, _ in test_loader:\n",
    "        encoded = autoencoder.encode(data)\n",
    "        X_test_encoded.append(encoded.cpu().numpy())\n",
    "\n",
    "X_test_encoded = np.vstack(X_test_encoded)\n",
    "print(X_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuning the ocsvms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_dbocsvm_fit_ocsvm(\n",
    "    trial: optuna.Trial,\n",
    "    model: DBOCSVM_V2,\n",
    "    X_encoded_train: np.ndarray,\n",
    "    X_encoded_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    cluster_count: int = 20,\n",
    ") -> float:\n",
    "\n",
    "    parameter_list = {}\n",
    "    for cluster in range(0, cluster_count):\n",
    "        hyperparameter = {\n",
    "            \"kernel\": \"rbf\",\n",
    "            \"gamma\": trial.suggest_float(f\"gamma_{cluster}\", 1e-4, 1.0),\n",
    "            \"nu\": trial.suggest_float(f\"nu_{cluster}\", 0.01, 0.5),\n",
    "        }\n",
    "        parameter_list[cluster] = hyperparameter\n",
    "\n",
    "    model.fit_ocsvm(X_encoded_train, parameter_list=parameter_list)\n",
    "\n",
    "    y_pred = model.predict(X_encoded_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def inner_objective_dbocsvm(\n",
    "    trial: optuna.Trial,\n",
    "    X_encoded: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    cluster_count: int = 20,\n",
    "    kfold_splits: int = 7,\n",
    "    eps: float = 1.5,\n",
    "    min_samples: int = 50,\n",
    "    tree_algorithm: str = \"kd_tree\",  # \"ball_tree\"\n",
    ") -> float:\n",
    "\n",
    "    parameter_list = {}\n",
    "    for cluster in range(0, cluster_count):\n",
    "        hyperparameter = {\n",
    "            \"kernel\": \"rbf\",\n",
    "            \"gamma\": trial.suggest_float(f\"gamma_{cluster}\", 1e-4, 1.0, log=True),\n",
    "            \"nu\": trial.suggest_float(f\"nu_{cluster}\", 0.01, 0.5),\n",
    "        }\n",
    "        parameter_list[cluster] = hyperparameter\n",
    "\n",
    "    kf = KFold(n_splits=kfold_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_encoded):\n",
    "        X_train, X_val = X_encoded[train_idx], X_encoded[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        X_train_normal = X_train[y_train == 1]\n",
    "\n",
    "        dbocsvm = DBOCSVM(\n",
    "            kernel=\"rbf\",\n",
    "            gamma=\"auto\",\n",
    "            nu=0.2,\n",
    "            eps=eps,\n",
    "            min_samples=min_samples,\n",
    "            algorithm=tree_algorithm,\n",
    "        )\n",
    "\n",
    "        dbocsvm.fit(X_train_normal, parameter_list=parameter_list)\n",
    "\n",
    "        y_pred = dbocsvm.predict(X_val)\n",
    "\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        scores.append(acc)\n",
    "\n",
    "    # TODO: write a different objective function but use the test set to evaluate the model\n",
    "    # Return mean acc score across all folds\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def outer_objective(\n",
    "    trial: optuna.Trial,\n",
    "    train_dataset: torch.utils.data.Dataset,\n",
    "    val_dataset: torch.utils.data.Dataset,\n",
    "    train_dataset_unsplit: pd.DataFrame,\n",
    "    input_dim: int,\n",
    "    seed: int = 42,\n",
    "    cudnn_deterministic: bool = False,\n",
    "    verbose: bool = False,\n",
    "    best_model_path=\"best_autoencoder_tuning.pth\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Outer objective function to optimize hyperparameters for an autoencoder-dbocsvm pipeline.\n",
    "\n",
    "    This function is used as an objective for Optuna's hyperparameter optimization.\n",
    "    It performs a nested optimization process:\n",
    "    1. Optimizes autoencoder architecture and training parameters\n",
    "    2. Trains the autoencoder with the suggested hyperparameters\n",
    "    3. If the autoencoder performs well, launches a nested optimization for dbocsvm parameters\n",
    "    4. Returns the performance metric of the best dbocsvm configuration\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial : optuna.Trial\n",
    "        Optuna trial object used for hyperparameter suggestion\n",
    "    train_dataset : torch.utils.data.Dataset\n",
    "        PyTorch dataset for autoencoder training\n",
    "    val_dataset : torch.utils.data.Dataset\n",
    "        PyTorch dataset for autoencoder validation\n",
    "    train_dataset_unsplit : pd.DataFrame\n",
    "        Original training data as DataFrame, used for OCSVM optimization\n",
    "    input_dim : int\n",
    "        Input dimension for the autoencoder\n",
    "    seed : int, default=42\n",
    "        Random seed for reproducibility\n",
    "    cudnn_deterministic : bool, default=False\n",
    "        Whether to make CUDNN deterministic (slower but more reproducible)\n",
    "    verbose : bool, default=False\n",
    "        Whether to print training progress\n",
    "    best_model_path : str, default=\"best_autoencoder_tuning.pth\"\n",
    "        Path to save the best autoencoder model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Performance metric of the best OCSVM model (higher is better)\n",
    "        Returns 0.0 if the autoencoder fails to achieve good reconstruction\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Autoencoder hyperparameters optimized:\n",
    "      - Number of hidden layers (1-3)\n",
    "      - Hidden dimensions (as fractions of input/previous layer)\n",
    "      - Latent dimension (as fraction of last hidden layer)\n",
    "      - Learning rate and batch size\n",
    "    - OCSVM hyperparameters optimized in the inner study:\n",
    "      - nu: Outlier fraction parameter\n",
    "      - gamma: RBF kernel parameter\n",
    "    - Early stopping is used when training the autoencoder\n",
    "    - Results are attached to the trial as user attributes for later analysis\n",
    "    \"\"\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    set_seed(seed, cudnn_deterministic)\n",
    "\n",
    "    # Autoencoder hyperparameters to optimize\n",
    "    num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 3)\n",
    "    hidden_dims = []\n",
    "    for i in range(num_hidden_layers):\n",
    "        hidden_factor = trial.suggest_float(f\"hidden_factor_{i}\", 0.3, 0.8)\n",
    "        prev_dim = input_dim if i == 0 else int(hidden_dims[-1])\n",
    "        hidden_dims.append(int(prev_dim * hidden_factor))\n",
    "\n",
    "    # Latent dimension as a fraction of the last hidden layer\n",
    "    latent_factor = trial.suggest_float(\"latent_factor\", 0.2, 0.8)\n",
    "    latent_dim = max(2, int(hidden_dims[-1] * latent_factor))\n",
    "\n",
    "    # Learning parameters\n",
    "    lr = trial.suggest_categorical(\"lr\", [0.1, 0.01, 0.001, 0.0001])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "\n",
    "    # NOTE: not using this\n",
    "    # activation_type = trial.suggest_categorical(\n",
    "    #     \"activation_type\", [\"ReLU\", \"LeakyReLU\", \"ELU\"]\n",
    "    # )\n",
    "    # output_activation_type = trial.suggest_categorical(\n",
    "    #     \"output_activation_type\", [None, \"Sigmoid\", \"Tanh\"]\n",
    "    # )\n",
    "    # weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    # optimizer_name = trial.suggest_categorical(\n",
    "    #     \"optimizer\", [\"Adam\", \"AdamW\", \"RMSprop\"]\n",
    "    # )\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Create model\n",
    "    model = BatchNormAutoencoder(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dims=hidden_dims,\n",
    "        latent_dim=latent_dim,\n",
    "        activation_type=\"LeakyReLU\",\n",
    "        output_activation_type=\"Sigmoid\",\n",
    "    )\n",
    "\n",
    "    # NOTE: not using this\n",
    "    # Select optimizer\n",
    "    # if optimizer_name == \"Adam\":\n",
    "    #     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    # elif optimizer_name == \"AdamW\":\n",
    "    #     optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    # else:\n",
    "    #     optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # loss and optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    history, is_good_model = train_autoencoder(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        epochs=50,\n",
    "        best_model_path=best_model_path,\n",
    "        verbose=True,\n",
    "        early_stopping_patience=5,\n",
    "        improvement_threshold=0.0001,\n",
    "        good_model_threshold=0.005,\n",
    "        plot_results=True,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Finished training autoencoder\")\n",
    "\n",
    "    if not is_good_model:\n",
    "        print(\"Skip dbscan tuning due to poor performance of autoencoder\")\n",
    "        return 0.0\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Autoencoder with hidden_dims: {hidden_dims}\")\n",
    "        print(f\"Autoencoder with latent_dim: {latent_dim}\")\n",
    "\n",
    "    # Load best model\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    # Extract encoded representation\n",
    "    X_dataset = ConcatDataset([train_dataset, val_dataset])\n",
    "    X_loader = DataLoader(X_dataset, batch_size=128)\n",
    "\n",
    "    # Extract in batches to prevent memory issues\n",
    "    X_encoded = []\n",
    "    with torch.no_grad():\n",
    "        for data in X_loader:\n",
    "            data_x = data[0].to(device)\n",
    "            encoded = model.encode(data_x)\n",
    "            X_encoded.append(encoded.cpu().numpy())\n",
    "    X_encoded = np.vstack(X_encoded)\n",
    "\n",
    "    input_dim_encoded = X_encoded.shape[1]\n",
    "\n",
    "    k_for_elbow = int((20 + input_dim_encoded * 2) / 2)\n",
    "    min_eps, max_eps = find_eps_range_with_elbow_method(\n",
    "        X_encoded,\n",
    "        k=k_for_elbow,\n",
    "        plot=False,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Starting DBSCAN tuning...\")\n",
    "\n",
    "    # Inner Optuna study for DBSCAN\n",
    "    score_threshold = 0.60\n",
    "    dbscan_objective_lambda = lambda trial: objective_dbscan(\n",
    "        trial,\n",
    "        X_encoded=X_encoded,\n",
    "        evaluation_metric=\"silhouette\",\n",
    "        eps_range=(min_eps, max_eps),\n",
    "        min_samples_range=(1, input_dim_encoded * 2),\n",
    "        distance_metric=\"euclidean\",  # REMOVE\n",
    "        score_threshold=score_threshold,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    dbscan_study = optuna.create_study(direction=\"maximize\")\n",
    "    dbscan_study.optimize(\n",
    "        dbscan_objective_lambda,\n",
    "        n_trials=10,\n",
    "    )\n",
    "\n",
    "    if dbscan_study.best_value < score_threshold:\n",
    "        print(\"Skip dbocsvm tuning due to poor performance of dbscan\")\n",
    "        return 0.0\n",
    "\n",
    "    # get dbscan best parameters\n",
    "    eps = dbscan_study.best_params[\"eps\"]\n",
    "    min_samples = dbscan_study.best_params[\"min_samples\"]\n",
    "\n",
    "    # get dbscan best trial\n",
    "    best_trial_dbscan = dbscan_study.best_trial\n",
    "    best_trial_dbscan_user_attrs = best_trial_dbscan.user_attrs\n",
    "\n",
    "    n_clusters = best_trial_dbscan_user_attrs[\"n_clusters\"]\n",
    "    cluster_data_points = best_trial_dbscan_user_attrs[\"cluster_data_points\"]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Finished training dbscan, with results:\")\n",
    "        print(f\"Best score: {best_trial_dbscan.value}\")\n",
    "        print(f\"Best parameters: {best_trial_dbscan.params}\")\n",
    "        print(f\"Best trial: {best_trial_dbscan.number}\")\n",
    "        print(f\"Number of clusters: {n_clusters}\")\n",
    "        print(f\"Cluster data points: {cluster_data_points}\")\n",
    "        print(\"\")\n",
    "\n",
    "    X_unsplit = train_dataset_unsplit.drop(\n",
    "        [\"attack_binary\", \"attack_categorical\", \"attack_class\"], axis=1\n",
    "    ).values\n",
    "    y_unsplit = train_dataset_unsplit[\"attack_binary\"].values\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_unsplit_tensor = torch.FloatTensor(X_unsplit)\n",
    "    X_unsplit_dataset = TensorDataset(X_unsplit_tensor)\n",
    "    X_unsplit_loader = DataLoader(X_unsplit_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "    # Extract encoded representation\n",
    "    # Extract in batches to prevent memory issues\n",
    "    X_encoded_unsplit = []\n",
    "    with torch.no_grad():\n",
    "        for data in X_unsplit_loader:\n",
    "            data_x = data[0].to(device)\n",
    "            encoded = model.encode(data_x)\n",
    "            X_encoded_unsplit.append(encoded.cpu().numpy())\n",
    "    X_encoded_unsplit = np.vstack(X_encoded_unsplit)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Starting DBOSVM tuning...\")\n",
    "        print(f\"with eps: {eps}, min_samples: {min_samples}, tree_algorithm: ball_tree\")\n",
    "    # Inner Optuna study for DBSCAN\n",
    "    dbocsvm_objective_lambda = lambda trial: inner_objective_dbocsvm(\n",
    "        trial,\n",
    "        X_encoded=X_encoded_unsplit,\n",
    "        y=y_unsplit,\n",
    "        cluster_count=n_clusters,\n",
    "        kfold_splits=7,\n",
    "        eps=eps,\n",
    "        min_samples=min_samples,\n",
    "        tree_algorithm=\"ball_tree\",\n",
    "    )\n",
    "    dbocsvm_study = optuna.create_study(direction=\"maximize\")\n",
    "    dbocsvm_study.optimize(\n",
    "        dbocsvm_objective_lambda,\n",
    "        n_trials=15,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Finished training DBOCSVM\")\n",
    "\n",
    "    best_dbocsvm_value = dbocsvm_study.best_value\n",
    "\n",
    "    best_dbscan_params = {\n",
    "        \"eps\": eps,\n",
    "        \"min_samples\": min_samples,\n",
    "    }\n",
    "    best_autoencoder_params = {\n",
    "        \"num_hidden_layers\": num_hidden_layers,\n",
    "        \"hidden_dims\": hidden_dims,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"lr\": lr,\n",
    "        \"batch_size\": batch_size,\n",
    "    }\n",
    "    best_autoencoder_val_loss = history[\"val_loss\"][-1]\n",
    "    best_dbocsvm_params = dbocsvm_study.best_params\n",
    "\n",
    "    # Store both autoencoder and DBOCSVM parameters for later reference\n",
    "    trial.set_user_attr(\"best_autoencoder_params\", best_autoencoder_params)\n",
    "    trial.set_user_attr(\"best_autoencoder_val_loss\", best_autoencoder_val_loss)\n",
    "    trial.set_user_attr(\"best_dbocsvm_params\", best_dbocsvm_params)\n",
    "    trial.set_user_attr(\"best_dbscan_params\", best_dbscan_params)\n",
    "\n",
    "    # Return DBOCSVM performance as the objective to maximize\n",
    "    return best_dbocsvm_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-07 02:48:23,071] A new study created in memory with name: no-name-f1cd137b-3f7d-4e33-ac6e-0064ca2dc657\n",
      "[I 2025-03-07 02:48:26,031] Trial 0 finished with value: 0.8317881382247261 and parameters: {'gamma_0': 0.47651606524039414, 'nu_0': 0.19718104254760194, 'gamma_1': 0.2857857443634166, 'nu_1': 0.267850015193371, 'gamma_2': 0.4478573986533414, 'nu_2': 0.10621361576158424, 'gamma_3': 0.762796675042166, 'nu_3': 0.4345902900141121, 'gamma_4': 0.9446072433236983, 'nu_4': 0.3494909223120462, 'gamma_5': 0.24019973927565313, 'nu_5': 0.38979493811007954}. Best is trial 0 with value: 0.8317881382247261.\n",
      "[I 2025-03-07 02:48:29,847] Trial 1 finished with value: 0.8870159251208801 and parameters: {'gamma_0': 0.7302808714979657, 'nu_0': 0.2835102063986876, 'gamma_1': 0.13716295627650854, 'nu_1': 0.03444963165247477, 'gamma_2': 0.2714481614594977, 'nu_2': 0.06193706707676016, 'gamma_3': 0.26773312178514497, 'nu_3': 0.3011929985057978, 'gamma_4': 0.694858535836481, 'nu_4': 0.4391555118715577, 'gamma_5': 0.6197832866145477, 'nu_5': 0.3936502984360944}. Best is trial 1 with value: 0.8870159251208801.\n",
      "[I 2025-03-07 02:48:33,814] Trial 2 finished with value: 0.8000709754691034 and parameters: {'gamma_0': 0.33712599365064505, 'nu_0': 0.43131176012562233, 'gamma_1': 0.6049544506039859, 'nu_1': 0.3165857697899371, 'gamma_2': 0.2066480081813997, 'nu_2': 0.2762837521508055, 'gamma_3': 0.3078114803998367, 'nu_3': 0.4566793205742035, 'gamma_4': 0.9116574315049089, 'nu_4': 0.3981003280587387, 'gamma_5': 0.2798101671215658, 'nu_5': 0.05890177380214757}. Best is trial 1 with value: 0.8870159251208801.\n",
      "[I 2025-03-07 02:48:36,744] Trial 3 finished with value: 0.8501530408552544 and parameters: {'gamma_0': 0.2023044255885142, 'nu_0': 0.2915932049920628, 'gamma_1': 0.5379563462342023, 'nu_1': 0.1934448403316803, 'gamma_2': 0.9315254625454817, 'nu_2': 0.06495966295775654, 'gamma_3': 0.7275926727436156, 'nu_3': 0.3264093001085322, 'gamma_4': 0.38627683392567613, 'nu_4': 0.3752911251527275, 'gamma_5': 0.08680733622067069, 'nu_5': 0.32172041009559993}. Best is trial 1 with value: 0.8870159251208801.\n",
      "[I 2025-03-07 02:48:39,069] Trial 4 finished with value: 0.8639488976622455 and parameters: {'gamma_0': 0.7884788867230349, 'nu_0': 0.17392545008572202, 'gamma_1': 0.4506797167170791, 'nu_1': 0.06915011621245093, 'gamma_2': 0.9811736984532525, 'nu_2': 0.36783681998523293, 'gamma_3': 0.029456977316595297, 'nu_3': 0.4236126288449736, 'gamma_4': 0.9672768679941361, 'nu_4': 0.4308915493606153, 'gamma_5': 0.9413121079514386, 'nu_5': 0.4651081854987801}. Best is trial 1 with value: 0.8870159251208801.\n",
      "[I 2025-03-07 02:48:41,668] Trial 5 finished with value: 0.7782903783879697 and parameters: {'gamma_0': 0.6584442081680091, 'nu_0': 0.19431019500161387, 'gamma_1': 0.3307565106545886, 'nu_1': 0.4041775845826884, 'gamma_2': 0.018190095308600277, 'nu_2': 0.370005519795624, 'gamma_3': 0.9848924444281997, 'nu_3': 0.1412056088978706, 'gamma_4': 0.019870718635780025, 'nu_4': 0.13391717396989247, 'gamma_5': 0.42597988103771733, 'nu_5': 0.1683301643735062}. Best is trial 1 with value: 0.8870159251208801.\n",
      "[W 2025-03-07 02:48:44,143] Trial 6 failed with parameters: {'gamma_0': 0.28511899026714627, 'nu_0': 0.48108953934032533, 'gamma_1': 0.02191773488212941, 'nu_1': 0.15293425169472663, 'gamma_2': 0.5326354385156188, 'nu_2': 0.26068845718598366, 'gamma_3': 0.8295891848064091, 'nu_3': 0.1516751520439156, 'gamma_4': 0.5070715553306269, 'nu_4': 0.09775000402219186, 'gamma_5': 0.8989614054112144, 'nu_5': 0.34869115127635214} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jbct/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_62281/1747832276.py\", line 2, in <lambda>\n",
      "    dbocsvm_fit_ocsvm_objective_lambda = lambda trial: objective_dbocsvm_fit_ocsvm(\n",
      "                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_62281/2704917921.py\", line 21, in objective_dbocsvm_fit_ocsvm\n",
      "    y_pred = model.predict(X_encoded_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_62281/1573873576.py\", line 406, in predict\n",
      "    predictions[i] = self.svms[cluster].predict([X[i]])[0]\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jbct/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/svm/_classes.py\", line 1820, in predict\n",
      "    y = super().predict(X)\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jbct/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 428, in predict\n",
      "    X = self._validate_for_predict(X)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jbct/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 606, in _validate_for_predict\n",
      "    X = self._validate_data(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jbct/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/base.py\", line 633, in _validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jbct/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/jbct/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 119, in _assert_all_finite\n",
      "    first_pass_isfinite = xp.isfinite(xp.sum(X))\n",
      "                                      ^^^^^^^^^\n",
      "  File \"/home/jbct/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py\", line 2485, in sum\n",
      "    return _wrapreduction(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/jbct/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py\", line 70, in _wrapreduction\n",
      "    passkwargs = {k: v for k, v in kwargs.items()\n",
      "                  ^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-07 02:48:44,149] Trial 6 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     dbocsvm_study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mdbocsvm_study\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdbocsvm_fit_ocsvm_objective_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocsvm_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Inner Optuna study for DBSCAN\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dbocsvm_fit_ocsvm_objective_lambda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective_dbocsvm_fit_ocsvm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdbocsvm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_encoded_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_encoded_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_storage_dbocsvm:\n\u001b[1;32m     12\u001b[0m     dbocsvm_study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m     13\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m         storage\u001b[38;5;241m=\u001b[39mocsvm_optuna_storage_path,\n\u001b[1;32m     15\u001b[0m         study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbocsvm_study\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m         load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[28], line 21\u001b[0m, in \u001b[0;36mobjective_dbocsvm_fit_ocsvm\u001b[0;34m(trial, model, X_encoded_train, X_encoded_test, y_test, cluster_count)\u001b[0m\n\u001b[1;32m     17\u001b[0m     parameter_list[cluster] \u001b[38;5;241m=\u001b[39m hyperparameter\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mfit_ocsvm(X_encoded_train, parameter_list\u001b[38;5;241m=\u001b[39mparameter_list)\n\u001b[0;32m---> 21\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_encoded_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc\n",
      "Cell \u001b[0;32mIn[22], line 406\u001b[0m, in \u001b[0;36mDBOCSVM_V2.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, cluster \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nearest_clusters):\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cluster \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvms:\n\u001b[0;32m--> 406\u001b[0m         predictions[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m         predictions[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Anomaly if no SVM for cluster\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/svm/_classes.py:1820\u001b[0m, in \u001b[0;36mOneClassSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform classification on samples in X.\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m \n\u001b[1;32m   1806\u001b[0m \u001b[38;5;124;03m    For a one-class model, +1 or -1 is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1818\u001b[0m \u001b[38;5;124;03m        Class labels for samples in X.\u001b[39;00m\n\u001b[1;32m   1819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1820\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/svm/_base.py:428\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    413\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/svm/_base.py:606\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    603\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 606\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    616\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:119\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 119\u001b[0m     first_pass_isfinite \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39misfinite(\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2485\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2482\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2486\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\n\u001b[1;32m   2488\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/thesis/db-ocsvm/venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:70\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapreduction\u001b[39m(obj, ufunc, method, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 70\u001b[0m     passkwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     71\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue}\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mu\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Inner Optuna study for DBSCAN\n",
    "dbocsvm_fit_ocsvm_objective_lambda = lambda trial: objective_dbocsvm_fit_ocsvm(\n",
    "    trial,\n",
    "    model=dbocsvm,\n",
    "    X_encoded_train=X_encoded,\n",
    "    X_encoded_test=X_test_encoded,\n",
    "    y_test=y_test,\n",
    "    cluster_count=n_clusters,\n",
    ")\n",
    "\n",
    "if with_storage_dbocsvm:\n",
    "    dbocsvm_study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        storage=ocsvm_optuna_storage_path,\n",
    "        study_name=\"dbocsvm_study\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    dbocsvm_study.optimize(\n",
    "        dbocsvm_fit_ocsvm_objective_lambda,\n",
    "        n_trials=ocsvm_trials,\n",
    "    )\n",
    "else:\n",
    "    dbocsvm_study = optuna.create_study(direction=\"maximize\")\n",
    "    dbocsvm_study.optimize(\n",
    "        dbocsvm_fit_ocsvm_objective_lambda,\n",
    "        n_trials=ocsvm_trials,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_list = {}\n",
    "\n",
    "for key, value in dbocsvm_study.best_params.items():\n",
    "    cluster = key.split(\"_\")[1]\n",
    "    cluster = int(cluster)\n",
    "\n",
    "    parameter_list[cluster] = {\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": dbocsvm_study.best_params[f\"gamma_{cluster}\"],\n",
    "        \"nu\": dbocsvm_study.best_params[f\"nu_{cluster}\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best parameters and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_existing_model:\n",
    "    autoencoder_architecture = {\n",
    "        \"input_dim\": existing_model_architecture[\"input_dim\"],\n",
    "        \"hidden_dims\": existing_model_architecture[\"hidden_dims\"],\n",
    "        \"latent_dim\": existing_model_architecture[\"latent_dim\"],\n",
    "        \"activation_type\": existing_model_architecture[\"activation_type\"],\n",
    "        \"output_activation_type\": existing_model_architecture[\"output_activation_type\"],\n",
    "        \"val_loss\": checkpoint[\"val_loss\"],\n",
    "    }\n",
    "else:\n",
    "    autoencoder_architecture = {\n",
    "        \"input_dim\": input_dim,\n",
    "        \"hidden_dims\": new_model_architecture[\"hidden_dims\"],\n",
    "        \"latent_dim\": new_model_architecture[\"latent_dim\"],\n",
    "        \"activation_type\": new_model_architecture[\"activation_type\"],\n",
    "        \"output_activation_type\": new_model_architecture[\"output_activation_type\"],\n",
    "        \"learning_rate\": new_model_learning_parameters[\"lr\"],\n",
    "        \"batch_size\": new_model_learning_parameters[\"batch_size\"],\n",
    "        \"epochs\": new_model_learning_parameters[\"epochs\"],\n",
    "        \"improvement_threshold\": new_model_learning_parameters[\"improvement_threshold\"],\n",
    "        \"good_model_threshold\": new_model_learning_parameters[\"good_model_threshold\"],\n",
    "        \"early_stopping_patience\": new_model_learning_parameters[\n",
    "            \"early_stopping_patience\"\n",
    "        ],\n",
    "        \"val_loss\": checkpoint[\"val_loss\"],\n",
    "    }\n",
    "\n",
    "print(\"Best autoencoder model:\")\n",
    "pprint.pprint(autoencoder_architecture, sort_dicts=False)\n",
    "print(\"\")\n",
    "\n",
    "best_dbscan_parameters = {\n",
    "    \"eps\": eps,\n",
    "    \"min_samples\": min_samples,\n",
    "    \"distance_metric\": dbscan_tuning_parameters[\"distance_metric\"],\n",
    "    \"evaluation_metric\": dbscan_tuning_parameters[\"evaluation_metric\"],\n",
    "    \"score\": best_trial_dbscan.value,\n",
    "}\n",
    "\n",
    "print(\"Best dbscan parameters\")\n",
    "pprint.pprint(best_dbscan_parameters, sort_dicts=False)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Best ocsvm parameters\")\n",
    "print(f\"Tree algorithm: {dbocsvm_tree_algorithm}\")\n",
    "print(f\"Accuracy: {dbocsvm_study.best_value}\")\n",
    "pprint.pprint(parameter_list, sort_dicts=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
