{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning with K fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_storage = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import KDTree, BallTree\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    ")\n",
    "\n",
    "\n",
    "class DBOCSVM:\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel=\"rbf\",\n",
    "        degree=3,\n",
    "        gamma=\"scale\",\n",
    "        coef0=0.0,\n",
    "        tol=0.001,\n",
    "        nu=0.5,\n",
    "        shrinking=True,\n",
    "        cache_size=200,\n",
    "        verbose=False,\n",
    "        max_iter=-1,\n",
    "        eps=0.5,\n",
    "        min_samples=10,\n",
    "        tree_metric=\"euclidean\",\n",
    "        dbscan_metric=\"euclidean\",\n",
    "        algorithm=\"kd_tree\",  # or 'ball_tree'\n",
    "        leaf_size=30,\n",
    "        n_jobs=-1,  # Add n_jobs parameter\n",
    "    ):\n",
    "        self.kernel = kernel\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "        self.coef0 = coef0\n",
    "        self.tol = tol\n",
    "        self.nu = nu\n",
    "        self.shrinking = shrinking\n",
    "        self.cache_size = cache_size\n",
    "        self.verbose = verbose\n",
    "        self.max_iter = max_iter\n",
    "        self.algorithm = algorithm\n",
    "        self.leaf_size = leaf_size\n",
    "        self.tree_metric = tree_metric\n",
    "        self.dbscan_metric = dbscan_metric\n",
    "        self.dbscan = DBSCAN(\n",
    "            eps=eps, min_samples=min_samples, n_jobs=n_jobs, metric=dbscan_metric\n",
    "        )  # Make it so that it can accept a metric parameter\n",
    "        self.svms = {}  # One SVM per cluster\n",
    "        self.dbscan_centroids = {}  # To store cluster centroids\n",
    "        self.cluster_points = {}  # Store points in each cluster\n",
    "        self.tree = None\n",
    "        # These attributes are mainly used for inspection purposes\n",
    "        self.cluster_sizes = {}  # Number of points in each cluster\n",
    "        self.n_jobs = n_jobs  # Store n_jobs\n",
    "        self.cluster_labels = None\n",
    "        self.unique_clusters = None\n",
    "\n",
    "    def fit_cluster(\n",
    "        self,\n",
    "        X,\n",
    "        dbscan_evaluation_metric=\"silhouette\",\n",
    "        dbscan_rerun=False,\n",
    "        dbscan_rerun_trials=10,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Training data\n",
    "        dbscan_evaluation_metric : str\n",
    "            Metric to optimize ('silhouette', 'davies_bouldin', or 'calinski_harabasz')\n",
    "        dbscan_rerun : bool\n",
    "            Whether to rerun DBSCAN after fitting the model with the best parameters\n",
    "        dbscan_rerun_trials : int\n",
    "            Number of reruns for DBSCAN after fitting the model with the best parameters\n",
    "        \"\"\"\n",
    "\n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "        \"\"\"\n",
    "        NOTE: Current DBSCAN only uses euclidean distance, so the metric parameter is not used\n",
    "        TODO: Add metric parameter to DBSCAN to handle different distance metrics\n",
    "        'euclidean': Standard Euclidean distance. This is the default metric.\n",
    "        'manhattan': Manhattan or L1 distance (sum of absolute differences).\n",
    "        'chebyshev': Chebyshev or maximum distance.\n",
    "        'minkowski': Minkowski distance, a generalization of Euclidean and Manhattan distance. The power parameter p of the Minkowski metric can be controlled by the p parameter of DBSCAN.\n",
    "        'wminkowski': Weighted Minkowski distance.\n",
    "        'seuclidean': Standardized Euclidean distance.\n",
    "        'mahalanobis': Mahalanobis distance.\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Fitting DBSCAN...\")\n",
    "        # NOTE: we use the dbscan that was initialized in the constructor\n",
    "        self.cluster_labels = self.dbscan.fit_predict(X)\n",
    "        if verbose:\n",
    "            print(\"DBSCAN Fitted...\")\n",
    "\n",
    "        if dbscan_rerun:\n",
    "            if verbose:\n",
    "                print(\"Rerunning DBSCAN...\")\n",
    "\n",
    "            if dbscan_evaluation_metric == \"silhouette\":\n",
    "                current_score = silhouette_score(X, self.cluster_labels)\n",
    "            elif dbscan_evaluation_metric == \"davies_bouldin\":\n",
    "                current_score = davies_bouldin_score(X, self.cluster_labels)\n",
    "            else:  # calinski_harabasz\n",
    "                current_score = calinski_harabasz_score(X, self.cluster_labels)\n",
    "\n",
    "            for i in range(dbscan_rerun_trials):\n",
    "                if verbose:\n",
    "                    print(f\"DBSCAN Rerun {i+1}...\")\n",
    "                new_cluster_labels = self.dbscan.fit_predict(X)\n",
    "\n",
    "                if dbscan_evaluation_metric == \"silhouette\":\n",
    "                    new_score = silhouette_score(X, new_cluster_labels)\n",
    "                    if new_score > current_score:\n",
    "                        self.cluster_labels = new_cluster_labels\n",
    "                        current_score = new_score\n",
    "                elif dbscan_evaluation_metric == \"davies_bouldin\":\n",
    "                    new_score = davies_bouldin_score(X, new_cluster_labels)\n",
    "                    if new_score < current_score:\n",
    "                        self.cluster_labels = new_cluster_labels\n",
    "                        current_score = new_score\n",
    "                else:  # calinski_harabasz\n",
    "                    new_score = calinski_harabasz_score(X, new_cluster_labels)\n",
    "                    if new_score > current_score:\n",
    "                        self.cluster_labels = new_cluster_labels\n",
    "                        current_score = new_score\n",
    "\n",
    "        self.unique_clusters = np.unique(self.cluster_labels)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Unique Clusters: {self.unique_clusters}\")\n",
    "\n",
    "        for cluster in self.unique_clusters:\n",
    "            # Store the number of points in the cluster\n",
    "            # mainly for inspection purposes\n",
    "            n_points = np.sum(self.cluster_labels == cluster)\n",
    "            self.cluster_sizes[int(cluster)] = int(n_points)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Cluster Sizes: {self.cluster_sizes}\")\n",
    "\n",
    "    def fit_ocsvm(\n",
    "        self,\n",
    "        X,\n",
    "        parameter_list=None,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Training data\n",
    "        parameter_list: dictionary of dictionaries\n",
    "            Each key in the dictionary is the cluster number and\n",
    "            the value is a dictionary containing the parameters for OCSVM\n",
    "            each dictionary looks like this:\n",
    "            {\n",
    "                0 : {\n",
    "                kernel: rbf, linear, poly, or sigmoid,\n",
    "                gamma: 'scale', 'auto' or a float,\n",
    "                nu: a float between 0 and 1 e.g 0.2,\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "        if parameter_list is None:\n",
    "            raise ValueError(\"parameter_list cannot be None\")\n",
    "\n",
    "        if len(parameter_list) < len(self.unique_clusters) - 1:\n",
    "            raise ValueError(\n",
    "                \"Number of parameters should be equal or greater than the number of clusters\"\n",
    "            )\n",
    "\n",
    "        def filter_dict(original_dict, keys_to_keep):\n",
    "            return {k: original_dict[k] for k in keys_to_keep if k in original_dict}\n",
    "\n",
    "        if len(parameter_list) >= len(self.unique_clusters) - 1:\n",
    "            cluster_count = list(self.cluster_sizes.keys())\n",
    "            cluster_count.remove(-1)\n",
    "            cluster_count\n",
    "\n",
    "            parameter_list = filter_dict(parameter_list, cluster_count)\n",
    "\n",
    "        for cluster in self.unique_clusters:\n",
    "\n",
    "            if cluster == -1:  # Skip noise cluster for SVM training\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Training for cluster {cluster} with {self.cluster_sizes[cluster]} points\"\n",
    "                )\n",
    "\n",
    "            # Boolean masking to get points in the current cluster\n",
    "            points = X[self.cluster_labels == cluster]\n",
    "            self.cluster_points[cluster] = points\n",
    "\n",
    "            if len(points) > 0:\n",
    "                # use parameters defined in constructor if not provided\n",
    "                if parameter_list is None:\n",
    "                    ocsvm = OneClassSVM(\n",
    "                        kernel=self.kernel,\n",
    "                        nu=self.nu,\n",
    "                        gamma=self.gamma,\n",
    "                        degree=self.degree,\n",
    "                        coef0=self.coef0,\n",
    "                        tol=self.tol,\n",
    "                        shrinking=self.shrinking,\n",
    "                        cache_size=self.cache_size,\n",
    "                        max_iter=self.max_iter,\n",
    "                    )\n",
    "                else:\n",
    "                    ocsvm = OneClassSVM(\n",
    "                        kernel=parameter_list[cluster][\"kernel\"],\n",
    "                        nu=parameter_list[cluster][\"nu\"],\n",
    "                        gamma=parameter_list[cluster][\"gamma\"],\n",
    "                        degree=self.degree,\n",
    "                        coef0=self.coef0,\n",
    "                        tol=self.tol,\n",
    "                        shrinking=self.shrinking,\n",
    "                        cache_size=self.cache_size,\n",
    "                        max_iter=self.max_iter,\n",
    "                    )\n",
    "                    if verbose:\n",
    "                        print(\n",
    "                            f\"OCSVM for cluster {cluster} uses nu: {parameter_list[cluster]['nu']}, gamma: {parameter_list[cluster]['gamma']}, kernel: {parameter_list[cluster]['kernel']}\"\n",
    "                        )\n",
    "                ocsvm.fit(points)\n",
    "\n",
    "                self.svms[cluster] = ocsvm\n",
    "\n",
    "                \"\"\"\n",
    "                TODO: Explore other alternatives for centroid calculation\n",
    "                \"->\" means the following line might be a downside of the current approach.\n",
    "                \n",
    "                - Median: More robust to outliers than the mean (`np.median(points, axis=0)`).\n",
    "                    -> Less representative if data is asymmetric  \n",
    "                - Trimmed Mean: Removes extreme values before computing the mean (`scipy.stats.trim_mean`).\n",
    "                    ->   Requires choosing the trimming percentage\n",
    "                - Weighted Mean: Assigns importance to points based on reliability.  \n",
    "                    ->  Requires defining weights\n",
    "                - Geometric Median: Minimizes sum of distances to all points. More robust to outliers than the mean.\n",
    "                    -> computationally expensive (`scipy.spatial`)\n",
    "                - Distance Metrics: Use median for Manhattan distance and mean for Euclidean distance.\n",
    "                    -> Requires choosing the distance metric\n",
    "                    \n",
    "                \"\"\"\n",
    "                self.dbscan_centroids[cluster] = np.mean(points, axis=0)\n",
    "\n",
    "        # Build tree with cluster centroids\n",
    "        centroids = [self.dbscan_centroids[c] for c in self.dbscan_centroids if c != -1]\n",
    "        self.valid_clusters = list(self.dbscan_centroids.keys())\n",
    "        if len(centroids) > 0:\n",
    "            centroids = np.array(centroids)\n",
    "            if self.algorithm == \"kd_tree\":\n",
    "                self.tree = KDTree(\n",
    "                    centroids, leaf_size=self.leaf_size, metric=self.tree_metric\n",
    "                )\n",
    "            elif self.algorithm == \"ball_tree\":\n",
    "                self.tree = BallTree(\n",
    "                    centroids, leaf_size=self.leaf_size, metric=self.tree_metric\n",
    "                )\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X,\n",
    "        dbscan_evaluation_metric=\"silhouette\",  # only used for reruns\n",
    "        dbscan_rerun=False,  # only used for reruns\n",
    "        dbscan_rerun_trials=10,  # only used for reruns\n",
    "        parameter_list=None,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "            Training data\n",
    "        dbscan_evaluation_metric : str\n",
    "            Metric to optimize ('silhouette', 'davies_bouldin', or 'calinski_harabasz')\n",
    "        dbscan_rerun : bool\n",
    "            Whether to rerun DBSCAN after fitting the model with the best parameters\n",
    "        dbscan_rerun_trials : int\n",
    "            Number of reruns for DBSCAN after fitting the model with the best parameters\n",
    "        parameter_list: dictionary of dictionaries\n",
    "            Each key in the dictionary is the cluster number and\n",
    "            the value is a dictionary containing the parameters for OCSVM\n",
    "            each dictionary looks like this:\n",
    "            {\n",
    "                0 : {\n",
    "                kernel: rbf, linear, poly, or sigmoid,\n",
    "                gamma: 'scale', 'auto' or a float,\n",
    "                nu: a float between 0 and 1 e.g 0.2,\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "\n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "        \"\"\"\n",
    "        NOTE: Current DBSCAN only uses euclidean distance, so the metric parameter is not used\n",
    "        TODO: Add metric parameter to DBSCAN to handle different distance metrics\n",
    "        'euclidean': Standard Euclidean distance. This is the default metric.\n",
    "        'manhattan': Manhattan or L1 distance (sum of absolute differences).\n",
    "        'chebyshev': Chebyshev or maximum distance.\n",
    "        'minkowski': Minkowski distance, a generalization of Euclidean and Manhattan distance. The power parameter p of the Minkowski metric can be controlled by the p parameter of DBSCAN.\n",
    "        'wminkowski': Weighted Minkowski distance.\n",
    "        'seuclidean': Standardized Euclidean distance.\n",
    "        'mahalanobis': Mahalanobis distance.\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Fitting DBSCAN...\")\n",
    "        # NOTE: we use the dbscan that was initialized in the constructor\n",
    "        cluster_labels = self.dbscan.fit_predict(X)\n",
    "        if verbose:\n",
    "            print(\"DBSCAN Fitted...\")\n",
    "\n",
    "        if dbscan_rerun:\n",
    "            if verbose:\n",
    "                print(\"Rerunning DBSCAN...\")\n",
    "\n",
    "            if dbscan_evaluation_metric == \"silhouette\":\n",
    "                current_score = silhouette_score(X, cluster_labels)\n",
    "            elif dbscan_evaluation_metric == \"davies_bouldin\":\n",
    "                current_score = davies_bouldin_score(X, cluster_labels)\n",
    "            else:  # calinski_harabasz\n",
    "                current_score = calinski_harabasz_score(X, cluster_labels)\n",
    "\n",
    "            for i in range(dbscan_rerun_trials):\n",
    "                if verbose:\n",
    "                    print(f\"DBSCAN Rerun {i+1}...\")\n",
    "\n",
    "                new_cluster_labels = self.dbscan.fit_predict(X)\n",
    "\n",
    "                if dbscan_evaluation_metric == \"silhouette\":\n",
    "                    new_score = silhouette_score(X, new_cluster_labels)\n",
    "                    if new_score > current_score:\n",
    "                        cluster_labels = new_cluster_labels\n",
    "                        current_score = new_score\n",
    "                elif dbscan_evaluation_metric == \"davies_bouldin\":\n",
    "                    new_score = davies_bouldin_score(X, new_cluster_labels)\n",
    "                    if new_score < current_score:\n",
    "                        cluster_labels = new_cluster_labels\n",
    "                        current_score = new_score\n",
    "                else:  # calinski_harabasz\n",
    "                    new_score = calinski_harabasz_score(X, new_cluster_labels)\n",
    "                    if new_score > current_score:\n",
    "                        cluster_labels = new_cluster_labels\n",
    "                        current_score = new_score\n",
    "\n",
    "        unique_clusters = np.unique(cluster_labels)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Unique Clusters: {unique_clusters}\")\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "            # Store the number of points in the cluster\n",
    "            # mainly for inspection purposes\n",
    "            n_points = np.sum(cluster_labels == cluster)\n",
    "            self.cluster_sizes[int(cluster)] = int(n_points)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Cluster Sizes: {self.cluster_sizes}\")\n",
    "\n",
    "        if parameter_list is not None and (len(parameter_list)) < (\n",
    "            len(unique_clusters) - 1\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Number of parameters should be equal or greater than the number of clusters\"\n",
    "            )\n",
    "\n",
    "        def filter_dict(original_dict, keys_to_keep):\n",
    "            return {k: original_dict[k] for k in keys_to_keep if k in original_dict}\n",
    "\n",
    "        if parameter_list is not None and (len(parameter_list)) >= (\n",
    "            len(unique_clusters) - 1\n",
    "        ):\n",
    "            cluster_count = list(self.cluster_sizes.keys())\n",
    "            cluster_count.remove(-1)\n",
    "            cluster_count\n",
    "\n",
    "            parameter_list = filter_dict(parameter_list, cluster_count)\n",
    "\n",
    "        self.parameter_list = parameter_list\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "\n",
    "            # Store the number of points in the cluster\n",
    "            # n_points = np.sum(cluster_labels == cluster)\n",
    "            # self.cluster_sizes[int(cluster)] = int(n_points)\n",
    "\n",
    "            if cluster == -1:  # Skip noise cluster for SVM training\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Training for cluster {cluster} with {self.cluster_sizes[cluster]} points\"\n",
    "                )\n",
    "\n",
    "            # Boolean masking to get points in the current cluster\n",
    "            points = X[cluster_labels == cluster]\n",
    "            self.cluster_points[cluster] = points\n",
    "\n",
    "            if len(points) > 0:\n",
    "                # use parameters defined in constructor if not provided\n",
    "                if parameter_list is None:\n",
    "                    ocsvm = OneClassSVM(\n",
    "                        kernel=self.kernel,\n",
    "                        nu=self.nu,\n",
    "                        gamma=self.gamma,\n",
    "                        degree=self.degree,\n",
    "                        coef0=self.coef0,\n",
    "                        tol=self.tol,\n",
    "                        shrinking=self.shrinking,\n",
    "                        cache_size=self.cache_size,\n",
    "                        max_iter=self.max_iter,\n",
    "                    )\n",
    "                else:\n",
    "                    ocsvm = OneClassSVM(\n",
    "                        kernel=parameter_list[cluster][\"kernel\"],\n",
    "                        nu=parameter_list[cluster][\"nu\"],\n",
    "                        gamma=parameter_list[cluster][\"gamma\"],\n",
    "                        degree=self.degree,\n",
    "                        coef0=self.coef0,\n",
    "                        tol=self.tol,\n",
    "                        shrinking=self.shrinking,\n",
    "                        cache_size=self.cache_size,\n",
    "                        max_iter=self.max_iter,\n",
    "                    )\n",
    "                    if verbose:\n",
    "                        print(\n",
    "                            f\"OCSVM for cluster {cluster} uses nu: {parameter_list[cluster]['nu']}, gamma: {parameter_list[cluster]['gamma']}, kernel: {parameter_list[cluster]['kernel']}\"\n",
    "                        )\n",
    "                ocsvm.fit(points)\n",
    "\n",
    "                self.svms[cluster] = ocsvm\n",
    "\n",
    "                \"\"\"\n",
    "                TODO: Explore other alternatives for centroid calculation\n",
    "                \"->\" means the following line might be a downside of the current approach.\n",
    "                \n",
    "                - Median: More robust to outliers than the mean (`np.median(points, axis=0)`).\n",
    "                    -> Less representative if data is asymmetric  \n",
    "                - Trimmed Mean: Removes extreme values before computing the mean (`scipy.stats.trim_mean`).\n",
    "                    ->   Requires choosing the trimming percentage\n",
    "                - Weighted Mean: Assigns importance to points based on reliability.  \n",
    "                    ->  Requires defining weights\n",
    "                - Geometric Median: Minimizes sum of distances to all points. More robust to outliers than the mean.\n",
    "                    -> computationally expensive (`scipy.spatial`)\n",
    "                - Distance Metrics: Use median for Manhattan distance and mean for Euclidean distance.\n",
    "                    -> Requires choosing the distance metric\n",
    "                    \n",
    "                \"\"\"\n",
    "                self.dbscan_centroids[cluster] = np.mean(points, axis=0)\n",
    "\n",
    "        # Build tree with cluster centroids\n",
    "        centroids = [self.dbscan_centroids[c] for c in self.dbscan_centroids if c != -1]\n",
    "        self.valid_clusters = list(self.dbscan_centroids.keys())\n",
    "        if len(centroids) > 0:\n",
    "            centroids = np.array(centroids)\n",
    "            if self.algorithm == \"kd_tree\":\n",
    "                self.tree = KDTree(\n",
    "                    centroids, leaf_size=self.leaf_size, metric=self.tree_metric\n",
    "                )\n",
    "            elif self.algorithm == \"ball_tree\":\n",
    "                self.tree = BallTree(\n",
    "                    centroids, leaf_size=self.leaf_size, metric=self.tree_metric\n",
    "                )\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.ones(len(X))\n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "        if self.tree is None:\n",
    "            return -1 * np.ones(len(X))\n",
    "\n",
    "        # Find nearest centroid\n",
    "        dist, ind = self.tree.query(X, k=1)\n",
    "        nearest_clusters = [self.valid_clusters[i] for i in ind.flatten()]\n",
    "\n",
    "        for i, cluster in enumerate(nearest_clusters):\n",
    "            if cluster in self.svms:\n",
    "                predictions[i] = self.svms[cluster].predict([X[i]])[0]\n",
    "            else:\n",
    "                predictions[i] = -1  # Anomaly if no SVM for cluster\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Classification Report on NSL-KDD:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Anomaly       0.57      1.00      0.73     12832\n",
    "      Normal       1.00      0.00      0.00      9711\n",
    "\n",
    "    accuracy                           0.57     22543\n",
    "   macro avg       0.78      0.50      0.36     22543\n",
    "weighted avg       0.75      0.57      0.41     22543\n",
    "\n",
    "Precision: 0.5693495429940545\n",
    "Recall: 1.0\n",
    "F1 Score: 0.7255866553576478\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Tuning on the validation set results in extreme overfitting\n",
    "Model performs better but only on the validation set, the test set results are worse\n",
    "Cannot use the full train set since it crashed the kernel\n",
    "TODO: Implement a better tuning strategy that generalizes well\n",
    "TODO: Explore other preprocessing steps e.g Autoencoder, Min-Max Normalization, Feature Selection\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_path = (\n",
    "    \"/home/jbct/Projects/thesis/db-ocsvm/data/processed/NSL-KDD/train_set_unsplit.csv\"\n",
    ")\n",
    "train_set = pd.read_csv(train_set_path)\n",
    "train_set = train_set.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
    "print(train_set.shape)\n",
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set.drop([\"attack_binary\", \"attack_categorical\", \"attack_class\"], axis=1)\n",
    "y = train_set[\"attack_binary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    parameter_list = {}\n",
    "    for cluster in range(0, 20):\n",
    "        hyperparameter = {\n",
    "            \"kernel\": \"rbf\",\n",
    "            \"gamma\": trial.suggest_float(f\"gamma_{cluster}\", 1e-4, 1.0, log=True),\n",
    "            \"nu\": trial.suggest_float(f\"nu_{cluster}\", 0.01, 0.5),\n",
    "        }\n",
    "        parameter_list[cluster] = hyperparameter\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "    # Store scores for each fold\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        X_train_normal = X_train[y_train == 1]\n",
    "\n",
    "        # if len(X_train_normal) > 31500:\n",
    "        #     X_train_normal = X_train_normal.sample(n=32000, random_state=42)\n",
    "\n",
    "        pca = PCA(n_components=69)\n",
    "        X_normal_pca = pca.fit_transform(X_train_normal)\n",
    "\n",
    "        X_train_normal = pd.DataFrame(\n",
    "            data=X_normal_pca,\n",
    "            columns=[f\"PC{i+1}\" for i in range(pca.n_components_)],\n",
    "            index=X_train_normal.index,  # This preserves the original index\n",
    "        )\n",
    "\n",
    "        dbocsvm = DBOCSVM(\n",
    "            kernel=\"rbf\",\n",
    "            gamma=\"auto\",\n",
    "            nu=0.2,\n",
    "            eps=8,\n",
    "            min_samples=5,\n",
    "            algorithm=\"ball_tree\",\n",
    "        )\n",
    "\n",
    "        dbocsvm.fit(X_train_normal.values, parameter_list=parameter_list)\n",
    "\n",
    "        X_val_pca = pca.transform(X_val)\n",
    "        X_val = pd.DataFrame(\n",
    "            data=X_val_pca,\n",
    "            columns=[f\"PC{i+1}\" for i in range(pca.n_components_)],\n",
    "            index=X_val.index,  # This preserves the original index\n",
    "        )\n",
    "\n",
    "        y_pred = dbocsvm.predict(X_val.values)\n",
    "\n",
    "        # Calculate F1 score for this fold\n",
    "        score = f1_score(y_val, y_pred, pos_label=-1)\n",
    "        scores.append(score)\n",
    "\n",
    "    # Return mean F1 score across all folds\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_path = \"sqlite:///optuna_storage/study_proposed_03.db\"\n",
    "trials = 7\n",
    "\n",
    "if with_storage:\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        storage=storage_path,\n",
    "        study_name=\"study_proposed_03\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(objective, n_trials=trials)\n",
    "else:\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best f1 score: {study.best_value:.3f}\")\n",
    "print(f\"Best parameters: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_list = {}\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    cluster = key.split(\"_\")[1]\n",
    "    cluster = int(cluster)\n",
    "\n",
    "    parameter_list[cluster] = {\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": study.best_params[f\"gamma_{cluster}\"],\n",
    "        \"nu\": study.best_params[f\"nu_{cluster}\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_full_path = (\n",
    "    \"/home/jbct/Projects/thesis/db-ocsvm/data/processed/NSL-KDD/train_set_full.csv\"\n",
    ")\n",
    "train_dataset_full = pd.read_csv(train_set_full_path)\n",
    "train_dataset_full = train_dataset_full.sample(frac=0.14, random_state=42).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "print(train_dataset_full.shape)\n",
    "train_dataset_full.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbocsvm = DBOCSVM(\n",
    "    kernel=\"rbf\",\n",
    "    gamma=\"auto\",\n",
    "    nu=0.2,\n",
    "    eps=8,\n",
    "    min_samples=5,\n",
    "    algorithm=\"ball_tree\",\n",
    ")\n",
    "print(dbocsvm.n_jobs)\n",
    "dbocsvm.fit(train_dataset_full.values, parameter_list=parameter_list, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_path = (\n",
    "    \"/home/jbct/Projects/thesis/db-ocsvm/data/processed/NSL-KDD/test_set.csv\"\n",
    ")\n",
    "\n",
    "test_set = pd.read_csv(test_set_path)\n",
    "print(f\"test set count: {test_set.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_set.drop(columns=[\"attack_binary\", \"attack_categorical\", \"attack_class\"])\n",
    "\n",
    "y_test = test_set[\"attack_binary\"]\n",
    "y_test_class = test_set[\"attack_class\"]\n",
    "print(y_test.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dbocsvm.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*y_pred[:10], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[-1, 1])\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title):\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels\n",
    "    )\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"Actual Label\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm, [\"Anomaly\", \"Normal\"], \"Confusion Matrix (Anomaly vs Normal)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Anomaly\", \"Normal\"]))\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=-1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=-1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=-1)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "log_file = \"/home/jbct/Projects/thesis/db-ocsvm/test.log.pca.json\"\n",
    "\n",
    "if acc > 0.84:\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    performance = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": acc,\n",
    "    }\n",
    "    data_to_save = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"parameters\": dbocsvm.parameter_list,\n",
    "        \"performance\": performance,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(log_file, \"r\") as f:\n",
    "            existing_data = json.load(f)\n",
    "\n",
    "        existing_data.append(data_to_save)\n",
    "    except json.JSONDecodeError:\n",
    "        existing_data = [data_to_save]\n",
    "\n",
    "    with open(log_file, \"w\") as f:\n",
    "        json.dump(existing_data, f, indent=4)\n",
    "\n",
    "    print(\"Paramters saved to log file\")\n",
    "else:\n",
    "    print(\"Parameters not saved to log file\")\n",
    "    print(\"Acc is below 0.85\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiclass_cm(y_true_class, y_pred_binary):\n",
    "    \"\"\"\n",
    "    Create a confusion matrix showing how each attack class was classified.\n",
    "\n",
    "    For attack classes (DoS, Probe, R2L, U2R), correct detection is when y_pred = -1 (anomaly)\n",
    "    For normal class, correct detection is when y_pred = 1 (normal)\n",
    "    \"\"\"\n",
    "    classes = np.unique(y_true_class)\n",
    "    cm = np.zeros((len(classes), 2))\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        # Get predictions for this class\n",
    "        cls_indices = y_true_class == cls\n",
    "        preds = y_pred_binary[cls_indices]\n",
    "\n",
    "        # Count correct and incorrect predictions\n",
    "        if cls == \"normal\":\n",
    "            cm[i, 0] = np.sum(preds == -1)  # incorrectly detected as anomaly\n",
    "            cm[i, 1] = np.sum(preds == 1)  # correctly detected as normal\n",
    "        else:\n",
    "            cm[i, 0] = np.sum(preds == -1)  # correctly detected as anomaly\n",
    "            cm[i, 1] = np.sum(preds == 1)  # incorrectly detected as normal\n",
    "\n",
    "    return cm, classes\n",
    "\n",
    "\n",
    "# Create and plot the multi-class confusion matrix\n",
    "cm_multi, classes = create_multiclass_cm(y_test_class, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm_multi,\n",
    "    annot=True,\n",
    "    fmt=\"g\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Detected as Anomaly\", \"Detected as Normal\"],\n",
    "    yticklabels=classes,\n",
    ")\n",
    "plt.ylabel(\"True Attack Class\")\n",
    "plt.title(\"Confusion Matrix by Attack Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate detection rates for each class\n",
    "print(\"Detection rates by class:\")\n",
    "class_metrics = {}\n",
    "for cls in np.unique(y_test_class):\n",
    "    # Get indices for this class\n",
    "    class_indices = y_test_class == cls\n",
    "\n",
    "    # True values and predictions for this class\n",
    "    y_true_cls = y_test[class_indices]\n",
    "    y_pred_cls = y_pred[class_indices]\n",
    "\n",
    "    # Calculate metrics\n",
    "    if cls == \"Normal\":\n",
    "        # For normal class, we want to detect 1 (normal)\n",
    "        correct = np.sum((y_pred_cls == 1))\n",
    "        precision = precision_score(\n",
    "            y_true_cls, y_pred_cls, pos_label=1, zero_division=0\n",
    "        )\n",
    "        recall = recall_score(y_true_cls, y_pred_cls, pos_label=1, zero_division=0)\n",
    "    else:\n",
    "        # For attack classes, we want to detect -1 (anomaly)\n",
    "        correct = np.sum((y_pred_cls == -1))\n",
    "        precision = precision_score(\n",
    "            y_true_cls, y_pred_cls, pos_label=-1, zero_division=0\n",
    "        )\n",
    "        recall = recall_score(y_true_cls, y_pred_cls, pos_label=-1, zero_division=0)\n",
    "\n",
    "    total = len(y_pred_cls)\n",
    "    detection_rate = correct / total\n",
    "    f1 = f1_score(\n",
    "        y_true_cls, y_pred_cls, pos_label=-1 if cls != \"Normal\" else 1, zero_division=0\n",
    "    )\n",
    "\n",
    "    class_metrics[cls] = {\n",
    "        \"detection_rate\": detection_rate,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"count\": total,\n",
    "        \"correctly_detected\": correct,\n",
    "    }\n",
    "\n",
    "    print(f\"{cls}: {detection_rate:.4f} ({correct}/{total})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
