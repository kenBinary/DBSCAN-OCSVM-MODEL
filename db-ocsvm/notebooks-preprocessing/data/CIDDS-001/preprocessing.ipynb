{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>proto</th>\n",
       "      <th>packets</th>\n",
       "      <th>bytes</th>\n",
       "      <th>flows</th>\n",
       "      <th>tcp_urg</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_psh</th>\n",
       "      <th>tcp_rst</th>\n",
       "      <th>tcp_syn</th>\n",
       "      <th>tcp_fin</th>\n",
       "      <th>tos</th>\n",
       "      <th>label</th>\n",
       "      <th>attack_type</th>\n",
       "      <th>attack_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018</td>\n",
       "      <td>TCP</td>\n",
       "      <td>2</td>\n",
       "      <td>338.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006</td>\n",
       "      <td>TCP</td>\n",
       "      <td>2</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019</td>\n",
       "      <td>TCP</td>\n",
       "      <td>2</td>\n",
       "      <td>338.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  proto  packets  bytes  flows  tcp_urg  tcp_ack  tcp_psh  tcp_rst  \\\n",
       "0     0.018  TCP          2  338.0      1        0        1        1        0   \n",
       "1     0.000  TCP          1  212.0      1        0        1        1        0   \n",
       "2     0.000  TCP          1  108.0      1        0        1        1        0   \n",
       "3     0.006  TCP          2  174.0      1        0        1        1        0   \n",
       "4     0.019  TCP          2  338.0      1        0        1        1        0   \n",
       "\n",
       "   tcp_syn  tcp_fin  tos   label attack_type  attack_id  \n",
       "0        0        0    0  normal      benign          0  \n",
       "1        0        0   32  normal      benign          0  \n",
       "2        0        0    0  normal      benign          0  \n",
       "3        0        0    0  normal      benign          0  \n",
       "4        0        0    0  normal      benign          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_dataset_path = (\n",
    "    \"D:\\\\projects\\\\School\\\\db-ocsvm\\\\data\\\\raw\\\\CIDDS-001\\\\cidds-001-openstack.parquet\"\n",
    ")\n",
    "dataset_pd_openstack = pd.read_parquet(raw_dataset_path)\n",
    "dataset_pd_openstack.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows before removing duplicates is: 4,161,690\n",
      "The number of rows after removing duplicates is: 4,161,690\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The number of rows before removing duplicates is: {dataset_pd_openstack.shape[0]:,}\"\n",
    ")\n",
    "dataset_pd_openstack.drop_duplicates(inplace=True)\n",
    "print(\n",
    "    f\"The number of rows after removing duplicates is: {dataset_pd_openstack.shape[0]:,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>proto</th>\n",
       "      <th>packets</th>\n",
       "      <th>bytes</th>\n",
       "      <th>flows</th>\n",
       "      <th>tcp_urg</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_psh</th>\n",
       "      <th>tcp_rst</th>\n",
       "      <th>tcp_syn</th>\n",
       "      <th>tcp_fin</th>\n",
       "      <th>tos</th>\n",
       "      <th>label</th>\n",
       "      <th>attack_type</th>\n",
       "      <th>attack_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018</td>\n",
       "      <td>TCP</td>\n",
       "      <td>2</td>\n",
       "      <td>338.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  proto  packets  bytes  flows  tcp_urg  tcp_ack  tcp_psh  tcp_rst  \\\n",
       "0     0.018  TCP          2  338.0      1        0        1        1        0   \n",
       "1     0.000  TCP          1  212.0      1        0        1        1        0   \n",
       "2     0.000  TCP          1  108.0      1        0        1        1        0   \n",
       "\n",
       "   tcp_syn  tcp_fin  tos   label attack_type  attack_id  \n",
       "0        0        0    0  normal      benign          0  \n",
       "1        0        0   32  normal      benign          0  \n",
       "2        0        0    0  normal      benign          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pd_openstack.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Applying 1-n Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying 1-n encoding to the categorical fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categorical fields in the dataset are: ['proto', 'label', 'attack_type']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = dataset_pd_openstack.select_dtypes(include=[\"category\"]).columns\n",
    "print(f\"The categorical fields in the dataset are: {list(categorical_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proto']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feature_columns = categorical_columns.tolist()\n",
    "categorical_feature_columns.remove(\"label\")\n",
    "categorical_feature_columns.remove(\"attack_type\")\n",
    "categorical_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4161690, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>packets</th>\n",
       "      <th>bytes</th>\n",
       "      <th>flows</th>\n",
       "      <th>tcp_urg</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_psh</th>\n",
       "      <th>tcp_rst</th>\n",
       "      <th>tcp_syn</th>\n",
       "      <th>tcp_fin</th>\n",
       "      <th>tos</th>\n",
       "      <th>label</th>\n",
       "      <th>attack_type</th>\n",
       "      <th>attack_id</th>\n",
       "      <th>proto_ICMP</th>\n",
       "      <th>proto_IGMP</th>\n",
       "      <th>proto_TCP</th>\n",
       "      <th>proto_UDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018</td>\n",
       "      <td>2</td>\n",
       "      <td>338.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  packets  bytes  flows  tcp_urg  tcp_ack  tcp_psh  tcp_rst  \\\n",
       "0     0.018        2  338.0      1        0        1        1        0   \n",
       "1     0.000        1  212.0      1        0        1        1        0   \n",
       "2     0.000        1  108.0      1        0        1        1        0   \n",
       "\n",
       "   tcp_syn  tcp_fin  tos   label attack_type  attack_id  proto_ICMP   \\\n",
       "0        0        0    0  normal      benign          0            0   \n",
       "1        0        0   32  normal      benign          0            0   \n",
       "2        0        0    0  normal      benign          0            0   \n",
       "\n",
       "   proto_IGMP   proto_TCP    proto_UDP    \n",
       "0            0            1            0  \n",
       "1            0            1            0  \n",
       "2            0            1            0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_encoded = pd.get_dummies(\n",
    "    dataset_pd_openstack, columns=categorical_feature_columns, dtype=int\n",
    ")\n",
    "print(dataset_encoded.shape)\n",
    "dataset_encoded.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimensions increase to 18 columns after 1-n encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary attack column (-1 for attacks, 1 for normal)\n",
    "dataset_encoded[\"attack_binary\"] = dataset_encoded[\"label\"].apply(\n",
    "    lambda x: 1 if x == \"normal\" else -1\n",
    ")\n",
    "dataset_encoded[\"attack_categorical\"] = dataset_encoded[\"attack_type\"]\n",
    "dataset_encoded.drop(\"label\", axis=1, inplace=True)\n",
    "dataset_encoded.drop(\"attack_type\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4161690, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>packets</th>\n",
       "      <th>bytes</th>\n",
       "      <th>flows</th>\n",
       "      <th>tcp_urg</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_psh</th>\n",
       "      <th>tcp_rst</th>\n",
       "      <th>tcp_syn</th>\n",
       "      <th>tcp_fin</th>\n",
       "      <th>tos</th>\n",
       "      <th>attack_id</th>\n",
       "      <th>proto_ICMP</th>\n",
       "      <th>proto_IGMP</th>\n",
       "      <th>proto_TCP</th>\n",
       "      <th>proto_UDP</th>\n",
       "      <th>attack_binary</th>\n",
       "      <th>attack_categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250155</th>\n",
       "      <td>0.100</td>\n",
       "      <td>4</td>\n",
       "      <td>575.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579537</th>\n",
       "      <td>0.072</td>\n",
       "      <td>2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966383</th>\n",
       "      <td>1.259</td>\n",
       "      <td>6</td>\n",
       "      <td>3912.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459811</th>\n",
       "      <td>0.716</td>\n",
       "      <td>7</td>\n",
       "      <td>6665.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361957</th>\n",
       "      <td>2.685</td>\n",
       "      <td>51</td>\n",
       "      <td>61973.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         duration  packets    bytes  flows  tcp_urg  tcp_ack  tcp_psh  \\\n",
       "250155      0.100        4    575.0      1        0        1        1   \n",
       "579537      0.072        2    138.0      1        0        0        0   \n",
       "2966383     1.259        6   3912.0      1        0        1        1   \n",
       "2459811     0.716        7   6665.0      1        0        1        1   \n",
       "1361957     2.685       51  61973.0      1        0        1        1   \n",
       "\n",
       "         tcp_rst  tcp_syn  tcp_fin  tos  attack_id  proto_ICMP   proto_IGMP   \\\n",
       "250155         0        1        0    0          0            0            0   \n",
       "579537         0        0        0    0          0            0            0   \n",
       "2966383        0        1        0   32          0            0            0   \n",
       "2459811        0        1        0   32          0            0            0   \n",
       "1361957        0        0        0   32          0            0            0   \n",
       "\n",
       "         proto_TCP    proto_UDP    attack_binary attack_categorical  \n",
       "250155             1            0              1             benign  \n",
       "579537             0            1              1             benign  \n",
       "2966383            1            0              1             benign  \n",
       "2459811            1            0              1             benign  \n",
       "1361957            1            0              1             benign  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset_encoded.shape)\n",
    "dataset_encoded.sample(n=5, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verify values of 'attack' field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_binary\n",
      " 1    4152916\n",
      "-1       8774\n",
      "Name: count, dtype: int64\n",
      "[ 1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_encoded[\"attack_binary\"].value_counts())\n",
    "print(dataset_encoded[\"attack_binary\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since there are 4 milion \"normal\" records and only 8.7k \"attack\" records, splitting needs to be methodological"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded[\"attack_binary\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset\n",
    "\n",
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "train_dataset_encoded, test_dataset_encoded = train_test_split(\n",
    "    dataset_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=dataset_encoded[\"attack_binary\"],\n",
    ")\n",
    "print(train_dataset_encoded.shape)\n",
    "print(test_dataset_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original dataset sizes:\")\n",
    "print(train_dataset_encoded.shape)\n",
    "print(test_dataset_encoded.shape)\n",
    "print(\"\\nOriginal attack distribution:\")\n",
    "print(\"Train dataset:\")\n",
    "print(train_dataset_encoded[\"attack_binary\"].value_counts())\n",
    "print(\"\\nTest dataset:\")\n",
    "print(test_dataset_encoded[\"attack_binary\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing and reducing attack records in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Separating normal from attack data\")\n",
    "train_normal = train_dataset_encoded[train_dataset_encoded[\"attack_binary\"] == 1]\n",
    "train_attack = train_dataset_encoded[train_dataset_encoded[\"attack_binary\"] == -1]\n",
    "print(train_normal.shape)\n",
    "print(train_attack.shape)\n",
    "print(\"\\nReducing normal records to only 180k records\")\n",
    "train_normal = train_normal.sample(n=180000, random_state=42).reset_index(drop=True)\n",
    "print(\"\\nNew train datset shape\")\n",
    "print(train_normal.shape)\n",
    "print(train_attack.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reducing test dataset and adding the attack records from the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal = test_dataset_encoded[test_dataset_encoded[\"attack_binary\"] == 1]\n",
    "test_attack = test_dataset_encoded[test_dataset_encoded[\"attack_binary\"] == -1]\n",
    "print(\"\\n Test dataset attack distribution\")\n",
    "print(test_normal.shape)\n",
    "print(test_attack.shape)\n",
    "print(\n",
    "    \"\\nReducing normal records to only 11226 records and concatenating the attack records from train set to test set\"\n",
    ")\n",
    "test_normal = test_normal.sample(n=11226, random_state=42)\n",
    "test_attack = pd.concat([test_attack, train_attack], ignore_index=True)\n",
    "print(\"\\nNew test dataset shape\")\n",
    "print(test_normal.shape)\n",
    "print(test_attack.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turning them back as one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_encoded = train_normal.copy()\n",
    "test_dataset_encoded = pd.concat([test_normal, test_attack], ignore_index=True)\n",
    "print(train_dataset_encoded.shape)\n",
    "print(test_dataset_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset_encoded[\"attack_binary\"].value_counts())\n",
    "print(\"Train dataset encoded\")\n",
    "train_dataset_encoded.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset_encoded[\"attack_binary\"].value_counts())\n",
    "print(\"Test dataset encoded\")\n",
    "test_dataset_encoded.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scaling (standard scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_type = \"robust\"  # minmax, standard, robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "if scaler_type == \"minmax\":\n",
    "    scaler = MinMaxScaler()\n",
    "    print(\"Using MinMaxScaler\")\n",
    "elif scaler_type == \"standard\":\n",
    "    scaler = StandardScaler()\n",
    "    print(\"Using StandardScaler\")\n",
    "elif scaler_type == \"robust\":\n",
    "    scaler = RobustScaler()\n",
    "    print(\"Using RobustScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_scaled = scaler.fit_transform(\n",
    "    train_dataset_encoded.drop(columns=[\"attack_binary\", \"attack_categorical\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the datast because the test dataset preprocessing will be done in a separate notebook\n",
    "import joblib\n",
    "\n",
    "scaler_path = \"/home/jbct/Projects/thesis/db-ocsvm/models/CIDDS-001/scaler.joblib\"\n",
    "joblib.dump(scaler, scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the normalized data back to a DataFrame\n",
    "train_dataset_scaled = pd.DataFrame(\n",
    "    train_dataset_scaled,\n",
    "    columns=train_dataset_encoded.columns.drop([\"attack_binary\", \"attack_categorical\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'attack' column back to the normalized DataFrame\n",
    "train_dataset_scaled[\"attack_binary\"] = train_dataset_encoded[\"attack_binary\"].values\n",
    "train_dataset_scaled[\"attack_categorical\"] = train_dataset_encoded[\n",
    "    \"attack_categorical\"\n",
    "].values\n",
    "print(train_dataset_scaled.shape)\n",
    "train_dataset_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_values = train_dataset_scaled.drop(\n",
    "    columns=[\"attack_binary\", \"attack_categorical\"]\n",
    ").min()\n",
    "max_values = train_dataset_scaled.drop(\n",
    "    columns=[\"attack_binary\", \"attack_categorical\"]\n",
    ").max()\n",
    "median_values = train_dataset_scaled.drop(\n",
    "    columns=[\"attack_binary\", \"attack_categorical\"]\n",
    ").median()\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "result = pd.DataFrame({\"min\": min_values, \"median\": median_values, \"max\": max_values})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_scaled = scaler.transform(\n",
    "    test_dataset_encoded.drop(columns=[\"attack_binary\", \"attack_categorical\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_scaled = pd.DataFrame(\n",
    "    test_dataset_scaled,\n",
    "    columns=train_dataset_encoded.columns.drop([\"attack_binary\", \"attack_categorical\"]),\n",
    ")\n",
    "\n",
    "# Add the 'attack' column back to the scaled DataFrame\n",
    "test_dataset_scaled[\"attack_binary\"] = test_dataset_encoded[\"attack_binary\"].values\n",
    "test_dataset_scaled[\"attack_categorical\"] = test_dataset_encoded[\n",
    "    \"attack_categorical\"\n",
    "].values\n",
    "print(\"\\nTest dataset shape\")\n",
    "print(test_dataset_scaled.shape)\n",
    "print(\"\\nTest dataset attack distribution (binary)\")\n",
    "print(test_dataset_scaled[\"attack_binary\"].value_counts())\n",
    "print(\"\\nTest dataset attack distribution (categorical)\")\n",
    "print(test_dataset_scaled[\"attack_categorical\"].value_counts())\n",
    "test_dataset_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_values = test_dataset_scaled.drop(\n",
    "    columns=[\"attack_binary\", \"attack_categorical\"]\n",
    ").min()\n",
    "max_values = test_dataset_scaled.drop(\n",
    "    columns=[\"attack_binary\", \"attack_categorical\"]\n",
    ").max()\n",
    "median_values = test_dataset_scaled.drop(\n",
    "    columns=[\"attack_binary\", \"attack_categorical\"]\n",
    ").median()\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "result = pd.DataFrame({\"min\": min_values, \"median\": median_values, \"max\": max_values})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Export Dataset to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full train dataset that only contains normal class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTran dataset shape\")\n",
    "print(train_dataset_scaled.shape)\n",
    "print(\"\\nTrain dataset attack distribution (binary)\")\n",
    "print(train_dataset_scaled[\"attack_binary\"].value_counts())\n",
    "train_dataset_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_scaled.to_csv(\n",
    "    DATASET[\"processed\"][\"CIDDS-001\"][\"train_full\"], index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTran dataset shape\")\n",
    "print(test_dataset_scaled.shape)\n",
    "print(\"\\nTrain dataset attack distribution (binary)\")\n",
    "print(test_dataset_scaled[\"attack_binary\"].value_counts())\n",
    "test_dataset_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_scaled.to_csv(DATASET[\"processed\"][\"CIDDS-001\"][\"test\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
